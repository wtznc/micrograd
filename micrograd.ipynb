{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanh derivative\n",
    "o = tanh(n)\n",
    "do/dn = 1 - o ** 2 (1 - tanh(n) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in a graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v._prev:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "  \n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    # for any value in the graph, create a rectangular ('record') node for it\n",
    "    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
    "    if n._op:\n",
    "      # if this value is a result of some operation, create an op node for it\n",
    "      dot.node(name = uid + n._op, label = n._op)\n",
    "      # and connect this node to it\n",
    "      dot.edge(uid + n._op, uid)\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    # connect n1 to the op node of n2\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "  return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  \n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = 0.0\n",
    "    self._backward = lambda: None\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Value(data={self.data})\"\n",
    "  \n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self, other), '+')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self, other), '*')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "      \n",
    "    return out\n",
    "  \n",
    "  def __pow__(self, other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "    out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "    def _backward():\n",
    "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def __rmul__(self, other): # other * self\n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other): # self / other\n",
    "    return self * other**-1\n",
    "\n",
    "  def __neg__(self): # -self\n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): # self - other\n",
    "    return self + (-other)\n",
    "\n",
    "  def __radd__(self, other): # other + self\n",
    "    return self + other\n",
    "\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def exp(self):\n",
    "    x = self.data\n",
    "    out = Value(math.exp(x), (self, ), 'exp')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  \n",
    "  def backward(self):\n",
    "    \n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "    \n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "      node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=2.0)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(1.0)\n",
    "a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-8.0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Value(2.0, label = 'a')\n",
    "b = Value(-3.0, label = 'b')\n",
    "c = Value(10.0, label = 'c')\n",
    "e = a * b; e.label = 'e'\n",
    "d = e + c; d.label = 'd'\n",
    "d\n",
    "f = Value(-2.0, label = 'f')\n",
    "L = d * f; L.label = 'L'\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = d * f\n",
    "dL/ dd = ? f\n",
    "\n",
    "(f(x+h) - f(x)) / h  \n",
    "((d+h)*f - d * f) / h  \n",
    "(d * f + h * x - d * f) / h  \n",
    "(h*f) / h  \n",
    "f  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(-5, 5, 0.2), np.tanh(np.arange(-5, 5, 0.2))); plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1,x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "# weights w1,w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "# bias of the neuron\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
    "x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "o = n.tanh(); o.label = 'o'\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = w1.data * x1w1.grad\n",
    "w1.grad = x1.data * x1w1.grad\n",
    "x2.grad = w2.data * x2w2.grad\n",
    "w2.grad = x2.data * x2w2.grad\n",
    "x1w1.grad = 0.5\n",
    "x2w2.grad = 0.5\n",
    "b.grad = 0.5\n",
    "x1w1x2w2.grad = 0.5\n",
    "n.grad = 0.5\n",
    "o.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 5.0.0 (20220707.1540)\n -->\n<!-- Pages: 1 -->\n<svg width=\"1575pt\" height=\"210pt\"\n viewBox=\"0.00 0.00 1575.00 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-206 1571,-206 1571,4 -4,4\"/>\n<!-- 4754202128 -->\n<g id=\"node1\" class=\"node\">\n<title>4754202128</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"326,-55.5 326,-91.5 546,-91.5 546,-55.5 326,-55.5\"/>\n<text text-anchor=\"middle\" x=\"352.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1*w1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"379,-55.5 379,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"421.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"464,-55.5 464,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"505\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5007888768+ -->\n<g id=\"node11\" class=\"node\">\n<title>5007888768+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"609\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"609\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 4754202128&#45;&gt;5007888768+ -->\n<g id=\"edge10\" class=\"edge\">\n<title>4754202128&#45;&gt;5007888768+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M546.27,-90.75C555.64,-92.23 564.6,-93.65 572.65,-94.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"572.23,-98.4 582.65,-96.5 573.32,-91.48 572.23,-98.4\"/>\n</g>\n<!-- 4754202128* -->\n<g id=\"node2\" class=\"node\">\n<title>4754202128*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"263\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"263\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 4754202128*&#45;&gt;4754202128 -->\n<g id=\"edge1\" class=\"edge\">\n<title>4754202128*&#45;&gt;4754202128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.34,-73.5C297.77,-73.5 306.37,-73.5 315.6,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"315.84,-77 325.84,-73.5 315.84,-70 315.84,-77\"/>\n</g>\n<!-- 4727906480 -->\n<g id=\"node3\" class=\"node\">\n<title>4727906480</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"4,-165.5 4,-201.5 196,-201.5 196,-165.5 4,-165.5\"/>\n<text text-anchor=\"middle\" x=\"19\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"34,-165.5 34,-201.5 \"/>\n<text text-anchor=\"middle\" x=\"74\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"114,-165.5 114,-201.5 \"/>\n<text text-anchor=\"middle\" x=\"155\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5007894768* -->\n<g id=\"node5\" class=\"node\">\n<title>5007894768*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"263\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"263\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 4727906480&#45;&gt;5007894768* -->\n<g id=\"edge13\" class=\"edge\">\n<title>4727906480&#45;&gt;5007894768*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.53,-165.44C181.84,-162.67 191.2,-159.67 200,-156.5 210.53,-152.71 221.75,-147.9 231.72,-143.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.25,-146.48 240.82,-139.07 230.28,-140.14 233.25,-146.48\"/>\n</g>\n<!-- 5007894768 -->\n<g id=\"node4\" class=\"node\">\n<title>5007894768</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"328.5,-110.5 328.5,-146.5 543.5,-146.5 543.5,-110.5 328.5,-110.5\"/>\n<text text-anchor=\"middle\" x=\"355\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">x2*w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"381.5,-110.5 381.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"421.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"461.5,-110.5 461.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"502.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5007894768&#45;&gt;5007888768+ -->\n<g id=\"edge9\" class=\"edge\">\n<title>5007894768&#45;&gt;5007888768+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M543.84,-111.01C554.01,-109.34 563.76,-107.74 572.44,-106.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"573.17,-109.75 582.47,-104.68 572.04,-102.84 573.17,-109.75\"/>\n</g>\n<!-- 5007894768*&#45;&gt;5007894768 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5007894768*&#45;&gt;5007894768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.34,-128.5C298.51,-128.5 308.08,-128.5 318.36,-128.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"318.39,-132 328.39,-128.5 318.39,-125 318.39,-132\"/>\n</g>\n<!-- 4725133648 -->\n<g id=\"node6\" class=\"node\">\n<title>4725133648</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 200,-91.5 200,-55.5 0,-55.5\"/>\n<text text-anchor=\"middle\" x=\"16.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">w1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"33,-55.5 33,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"75.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"118,-55.5 118,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 4725133648&#45;&gt;4754202128* -->\n<g id=\"edge12\" class=\"edge\">\n<title>4725133648&#45;&gt;4754202128*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M200.21,-73.5C209.2,-73.5 217.86,-73.5 225.7,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.85,-77 235.85,-73.5 225.85,-70 225.85,-77\"/>\n</g>\n<!-- 4725137248 -->\n<g id=\"node7\" class=\"node\">\n<title>4725137248</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2,-0.5 2,-36.5 198,-36.5 198,-0.5 2,-0.5\"/>\n<text text-anchor=\"middle\" x=\"17\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"32,-0.5 32,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"112,-0.5 112,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"155\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;1.5000</text>\n</g>\n<!-- 4725137248&#45;&gt;4754202128* -->\n<g id=\"edge11\" class=\"edge\">\n<title>4725137248&#45;&gt;4754202128*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.28,-36.5C179.65,-39.61 190.16,-42.98 200,-46.5 210.28,-50.17 221.28,-54.74 231.11,-59.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"229.93,-62.37 240.48,-63.27 232.79,-55.99 229.93,-62.37\"/>\n</g>\n<!-- 5007885168 -->\n<g id=\"node8\" class=\"node\">\n<title>5007885168</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1382,-109.5 1382,-145.5 1567,-145.5 1567,-109.5 1382,-109.5\"/>\n<text text-anchor=\"middle\" x=\"1393.5\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1405,-109.5 1405,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1445\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.7071</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1485,-109.5 1485,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1526\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 5007885168tanh -->\n<g id=\"node9\" class=\"node\">\n<title>5007885168tanh</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1319\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1319\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n</g>\n<!-- 5007885168tanh&#45;&gt;5007885168 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5007885168tanh&#45;&gt;5007885168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1346.04,-127.5C1353.58,-127.5 1362.3,-127.5 1371.57,-127.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1371.81,-131 1381.81,-127.5 1371.81,-124 1371.81,-131\"/>\n</g>\n<!-- 5007888768 -->\n<g id=\"node10\" class=\"node\">\n<title>5007888768</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"672,-82.5 672,-118.5 945,-118.5 945,-82.5 672,-82.5\"/>\n<text text-anchor=\"middle\" x=\"725\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1*w1 + x2*w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"778,-82.5 778,-118.5 \"/>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"863,-82.5 863,-118.5 \"/>\n<text text-anchor=\"middle\" x=\"904\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5007892896+ -->\n<g id=\"node14\" class=\"node\">\n<title>5007892896+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1008\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1008\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 5007888768&#45;&gt;5007892896+ -->\n<g id=\"edge6\" class=\"edge\">\n<title>5007888768&#45;&gt;5007892896+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M941.24,-118.51C952.12,-120 962.4,-121.4 971.45,-122.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"971.11,-126.13 981.49,-124.01 972.05,-119.19 971.11,-126.13\"/>\n</g>\n<!-- 5007888768+&#45;&gt;5007888768 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5007888768+&#45;&gt;5007888768</title>\n<path fill=\"none\" stroke=\"black\" d=\"M636.23,-100.5C643.7,-100.5 652.41,-100.5 661.87,-100.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"661.98,-104 671.98,-100.5 661.98,-97 661.98,-104\"/>\n</g>\n<!-- 4725134224 -->\n<g id=\"node12\" class=\"node\">\n<title>4725134224</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2.5,-110.5 2.5,-146.5 197.5,-146.5 197.5,-110.5 2.5,-110.5\"/>\n<text text-anchor=\"middle\" x=\"19\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"35.5,-110.5 35.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"75.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"115.5,-110.5 115.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"156.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n</g>\n<!-- 4725134224&#45;&gt;5007894768* -->\n<g id=\"edge14\" class=\"edge\">\n<title>4725134224&#45;&gt;5007894768*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M197.91,-128.5C207.65,-128.5 217.05,-128.5 225.52,-128.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.7,-132 235.7,-128.5 225.7,-125 225.7,-132\"/>\n</g>\n<!-- 5007892896 -->\n<g id=\"node13\" class=\"node\">\n<title>5007892896</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1071,-109.5 1071,-145.5 1256,-145.5 1256,-109.5 1071,-109.5\"/>\n<text text-anchor=\"middle\" x=\"1082.5\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">n</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1094,-109.5 1094,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1134\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.8814</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1174,-109.5 1174,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1215\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5007892896&#45;&gt;5007885168tanh -->\n<g id=\"edge8\" class=\"edge\">\n<title>5007892896&#45;&gt;5007885168tanh</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1256.01,-127.5C1265.01,-127.5 1273.74,-127.5 1281.66,-127.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1281.91,-131 1291.91,-127.5 1281.91,-124 1281.91,-131\"/>\n</g>\n<!-- 5007892896+&#45;&gt;5007892896 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5007892896+&#45;&gt;5007892896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1035.04,-127.5C1042.58,-127.5 1051.3,-127.5 1060.57,-127.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1060.81,-131 1070.81,-127.5 1060.81,-124 1060.81,-131\"/>\n</g>\n<!-- 4725129568 -->\n<g id=\"node15\" class=\"node\">\n<title>4725129568</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"716,-137.5 716,-173.5 901,-173.5 901,-137.5 716,-137.5\"/>\n<text text-anchor=\"middle\" x=\"727.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"739,-137.5 739,-173.5 \"/>\n<text text-anchor=\"middle\" x=\"779\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 6.8814</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"819,-137.5 819,-173.5 \"/>\n<text text-anchor=\"middle\" x=\"860\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 4725129568&#45;&gt;5007892896+ -->\n<g id=\"edge7\" class=\"edge\">\n<title>4725129568&#45;&gt;5007892896+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M901.02,-142.52C926,-138.98 951.59,-135.36 971.37,-132.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"972.03,-135.99 981.43,-131.12 971.04,-129.06 972.03,-135.99\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x119ce2260>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 5.0.0 (20220707.1540)\n -->\n<!-- Pages: 1 -->\n<svg width=\"2944pt\" height=\"236pt\"\n viewBox=\"0.00 0.00 2944.00 236.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 232)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-232 2940,-232 2940,4 -4,4\"/>\n<!-- 5086093776 -->\n<g id=\"node1\" class=\"node\">\n<title>5086093776</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1072.5,-164.5 1072.5,-200.5 1254.5,-200.5 1254.5,-164.5 1072.5,-164.5\"/>\n<text text-anchor=\"middle\" x=\"1082.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1092.5,-164.5 1092.5,-200.5 \"/>\n<text text-anchor=\"middle\" x=\"1132.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1172.5,-164.5 1172.5,-200.5 \"/>\n<text text-anchor=\"middle\" x=\"1213.5\" y=\"-178.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.2203</text>\n</g>\n<!-- 5086099584* -->\n<g id=\"node9\" class=\"node\">\n<title>5086099584*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1319\" cy=\"-154.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1319\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 5086093776&#45;&gt;5086099584* -->\n<g id=\"edge11\" class=\"edge\">\n<title>5086093776&#45;&gt;5086099584*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1254.68,-166.05C1264.61,-164.24 1274.23,-162.48 1282.84,-160.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1283.6,-164.33 1292.81,-159.09 1282.35,-157.45 1283.6,-164.33\"/>\n</g>\n<!-- 5086089264 -->\n<g id=\"node2\" class=\"node\">\n<title>5086089264</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2225,-163.5 2225,-199.5 2407,-199.5 2407,-163.5 2225,-163.5\"/>\n<text text-anchor=\"middle\" x=\"2235\" y=\"-177.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2245,-163.5 2245,-199.5 \"/>\n<text text-anchor=\"middle\" x=\"2285\" y=\"-177.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 4.8284</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2325,-163.5 2325,-199.5 \"/>\n<text text-anchor=\"middle\" x=\"2366\" y=\"-177.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.1464</text>\n</g>\n<!-- 5086086096* -->\n<g id=\"node26\" class=\"node\">\n<title>5086086096*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2688\" cy=\"-153.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2688\" y=\"-149.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 5086089264&#45;&gt;5086086096* -->\n<g id=\"edge22\" class=\"edge\">\n<title>5086089264&#45;&gt;5086086096*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2407.31,-174.9C2468.7,-170.37 2551.76,-164.19 2625,-158.5 2633.42,-157.85 2642.48,-157.13 2651.01,-156.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2651.37,-159.92 2661.06,-155.63 2650.81,-152.94 2651.37,-159.92\"/>\n</g>\n<!-- 5086089264+ -->\n<g id=\"node3\" class=\"node\">\n<title>5086089264+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1940\" cy=\"-181.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1940\" y=\"-177.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 5086089264+&#45;&gt;5086089264 -->\n<g id=\"edge1\" class=\"edge\">\n<title>5086089264+&#45;&gt;5086089264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1967,-181.5C2017.46,-181.5 2131.06,-181.5 2214.81,-181.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2214.87,-185 2224.87,-181.5 2214.87,-178 2214.87,-185\"/>\n</g>\n<!-- 5086093344 -->\n<g id=\"node4\" class=\"node\">\n<title>5086093344</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"716,-137.5 716,-173.5 901,-173.5 901,-137.5 716,-137.5\"/>\n<text text-anchor=\"middle\" x=\"727.5\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"739,-137.5 739,-173.5 \"/>\n<text text-anchor=\"middle\" x=\"779\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 6.8814</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"819,-137.5 819,-173.5 \"/>\n<text text-anchor=\"middle\" x=\"860\" y=\"-151.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086098000+ -->\n<g id=\"node6\" class=\"node\">\n<title>5086098000+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1008\" cy=\"-127.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1008\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 5086093344&#45;&gt;5086098000+ -->\n<g id=\"edge28\" class=\"edge\">\n<title>5086093344&#45;&gt;5086098000+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M901.02,-142.52C926,-138.98 951.59,-135.36 971.37,-132.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"972.03,-135.99 981.43,-131.12 971.04,-129.06 972.03,-135.99\"/>\n</g>\n<!-- 5086098000 -->\n<g id=\"node5\" class=\"node\">\n<title>5086098000</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1071,-109.5 1071,-145.5 1256,-145.5 1256,-109.5 1071,-109.5\"/>\n<text text-anchor=\"middle\" x=\"1082.5\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">n</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1094,-109.5 1094,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1134\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.8814</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1174,-109.5 1174,-145.5 \"/>\n<text text-anchor=\"middle\" x=\"1215\" y=\"-123.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086098000&#45;&gt;5086099584* -->\n<g id=\"edge24\" class=\"edge\">\n<title>5086098000&#45;&gt;5086099584*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1256.01,-143.6C1265.49,-145.26 1274.66,-146.88 1282.9,-148.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1282.36,-151.78 1292.81,-150.07 1283.57,-144.89 1282.36,-151.78\"/>\n</g>\n<!-- 5086098000+&#45;&gt;5086098000 -->\n<g id=\"edge2\" class=\"edge\">\n<title>5086098000+&#45;&gt;5086098000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1035.04,-127.5C1042.58,-127.5 1051.3,-127.5 1060.57,-127.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1060.81,-131 1070.81,-127.5 1060.81,-124 1060.81,-131\"/>\n</g>\n<!-- 5086100016 -->\n<g id=\"node7\" class=\"node\">\n<title>5086100016</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1690.5,-81.5 1690.5,-117.5 1876.5,-117.5 1876.5,-81.5 1690.5,-81.5\"/>\n<text text-anchor=\"middle\" x=\"1700.5\" y=\"-95.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1710.5,-81.5 1710.5,-117.5 \"/>\n<text text-anchor=\"middle\" x=\"1750.5\" y=\"-95.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1790.5,-81.5 1790.5,-117.5 \"/>\n<text text-anchor=\"middle\" x=\"1833.5\" y=\"-95.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1036</text>\n</g>\n<!-- 5086086960+ -->\n<g id=\"node20\" class=\"node\">\n<title>5086086960+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1940\" cy=\"-126.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1940\" y=\"-122.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 5086100016&#45;&gt;5086086960+ -->\n<g id=\"edge23\" class=\"edge\">\n<title>5086100016&#45;&gt;5086086960+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1876.6,-115.6C1886.15,-117.26 1895.37,-118.88 1903.68,-120.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1903.2,-123.8 1913.65,-122.07 1904.4,-116.9 1903.2,-123.8\"/>\n</g>\n<!-- 5086099584 -->\n<g id=\"node8\" class=\"node\">\n<title>5086099584</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1382,-136.5 1382,-172.5 1564,-172.5 1564,-136.5 1382,-136.5\"/>\n<text text-anchor=\"middle\" x=\"1392\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1402,-136.5 1402,-172.5 \"/>\n<text text-anchor=\"middle\" x=\"1442\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.7627</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1482,-136.5 1482,-172.5 \"/>\n<text text-anchor=\"middle\" x=\"1523\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.2500</text>\n</g>\n<!-- 5086093104exp -->\n<g id=\"node13\" class=\"node\">\n<title>5086093104exp</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1627\" cy=\"-154.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1627\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">exp</text>\n</g>\n<!-- 5086099584&#45;&gt;5086093104exp -->\n<g id=\"edge26\" class=\"edge\">\n<title>5086099584&#45;&gt;5086093104exp</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1564.18,-154.5C1573.14,-154.5 1581.83,-154.5 1589.73,-154.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1589.96,-158 1599.96,-154.5 1589.96,-151 1589.96,-158\"/>\n</g>\n<!-- 5086099584*&#45;&gt;5086099584 -->\n<g id=\"edge3\" class=\"edge\">\n<title>5086099584*&#45;&gt;5086099584</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1346.13,-154.5C1353.67,-154.5 1362.39,-154.5 1371.64,-154.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1371.87,-158 1381.87,-154.5 1371.87,-151 1371.87,-158\"/>\n</g>\n<!-- 5086091472 -->\n<g id=\"node10\" class=\"node\">\n<title>5086091472</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 200,-91.5 200,-55.5 0,-55.5\"/>\n<text text-anchor=\"middle\" x=\"16.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">w1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"33,-55.5 33,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"75.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"118,-55.5 118,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"159\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 5086100448* -->\n<g id=\"node28\" class=\"node\">\n<title>5086100448*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"263\" cy=\"-73.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"263\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 5086091472&#45;&gt;5086100448* -->\n<g id=\"edge12\" class=\"edge\">\n<title>5086091472&#45;&gt;5086100448*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M200.21,-73.5C209.2,-73.5 217.86,-73.5 225.7,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.85,-77 235.85,-73.5 225.85,-70 225.85,-77\"/>\n</g>\n<!-- 5086091520 -->\n<g id=\"node11\" class=\"node\">\n<title>5086091520</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1690,-191.5 1690,-227.5 1877,-227.5 1877,-191.5 1690,-191.5\"/>\n<text text-anchor=\"middle\" x=\"1700\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1710,-191.5 1710,-227.5 \"/>\n<text text-anchor=\"middle\" x=\"1752.5\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;1.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1795,-191.5 1795,-227.5 \"/>\n<text text-anchor=\"middle\" x=\"1836\" y=\"-205.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.1464</text>\n</g>\n<!-- 5086091520&#45;&gt;5086089264+ -->\n<g id=\"edge17\" class=\"edge\">\n<title>5086091520&#45;&gt;5086089264+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1877.05,-192.73C1886.54,-191.01 1895.71,-189.35 1903.95,-187.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1904.64,-191.28 1913.85,-186.06 1903.39,-184.4 1904.64,-191.28\"/>\n</g>\n<!-- 5086093104 -->\n<g id=\"node12\" class=\"node\">\n<title>5086093104</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"1692.5,-136.5 1692.5,-172.5 1874.5,-172.5 1874.5,-136.5 1692.5,-136.5\"/>\n<text text-anchor=\"middle\" x=\"1702.5\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1712.5,-136.5 1712.5,-172.5 \"/>\n<text text-anchor=\"middle\" x=\"1752.5\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 5.8284</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"1792.5,-136.5 1792.5,-172.5 \"/>\n<text text-anchor=\"middle\" x=\"1833.5\" y=\"-150.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0429</text>\n</g>\n<!-- 5086093104&#45;&gt;5086089264+ -->\n<g id=\"edge20\" class=\"edge\">\n<title>5086093104&#45;&gt;5086089264+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1874.82,-170.28C1885.07,-172.08 1895.01,-173.81 1903.88,-175.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1903.3,-178.81 1913.75,-177.09 1904.5,-171.92 1903.3,-178.81\"/>\n</g>\n<!-- 5086093104&#45;&gt;5086086960+ -->\n<g id=\"edge15\" class=\"edge\">\n<title>5086093104&#45;&gt;5086086960+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1874.82,-138.13C1885.07,-136.27 1895.01,-134.47 1903.88,-132.87\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1904.54,-136.3 1913.75,-131.08 1903.29,-129.42 1904.54,-136.3\"/>\n</g>\n<!-- 5086093104exp&#45;&gt;5086093104 -->\n<g id=\"edge4\" class=\"edge\">\n<title>5086093104exp&#45;&gt;5086093104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1654.21,-154.5C1662.34,-154.5 1671.85,-154.5 1681.94,-154.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1682.19,-158 1692.19,-154.5 1682.19,-151 1682.19,-158\"/>\n</g>\n<!-- 5086097712 -->\n<g id=\"node14\" class=\"node\">\n<title>5086097712</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"328.5,-110.5 328.5,-146.5 543.5,-146.5 543.5,-110.5 328.5,-110.5\"/>\n<text text-anchor=\"middle\" x=\"355\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">x2*w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"381.5,-110.5 381.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"421.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"461.5,-110.5 461.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"502.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086085568+ -->\n<g id=\"node24\" class=\"node\">\n<title>5086085568+</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"609\" cy=\"-100.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"609\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n</g>\n<!-- 5086097712&#45;&gt;5086085568+ -->\n<g id=\"edge21\" class=\"edge\">\n<title>5086097712&#45;&gt;5086085568+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M543.84,-111.01C554.01,-109.34 563.76,-107.74 572.44,-106.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"573.17,-109.75 582.47,-104.68 572.04,-102.84 573.17,-109.75\"/>\n</g>\n<!-- 5086097712* -->\n<g id=\"node15\" class=\"node\">\n<title>5086097712*</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"263\" cy=\"-128.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"263\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n</g>\n<!-- 5086097712*&#45;&gt;5086097712 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5086097712*&#45;&gt;5086097712</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.34,-128.5C298.51,-128.5 308.08,-128.5 318.36,-128.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"318.39,-132 328.39,-128.5 318.39,-125 318.39,-132\"/>\n</g>\n<!-- 5086095696 -->\n<g id=\"node16\" class=\"node\">\n<title>5086095696</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"4,-165.5 4,-201.5 196,-201.5 196,-165.5 4,-165.5\"/>\n<text text-anchor=\"middle\" x=\"19\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"34,-165.5 34,-201.5 \"/>\n<text text-anchor=\"middle\" x=\"74\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"114,-165.5 114,-201.5 \"/>\n<text text-anchor=\"middle\" x=\"155\" y=\"-179.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086095696&#45;&gt;5086097712* -->\n<g id=\"edge16\" class=\"edge\">\n<title>5086095696&#45;&gt;5086097712*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.53,-165.44C181.84,-162.67 191.2,-159.67 200,-156.5 210.53,-152.71 221.75,-147.9 231.72,-143.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"233.25,-146.48 240.82,-139.07 230.28,-140.14 233.25,-146.48\"/>\n</g>\n<!-- 5086100784 -->\n<g id=\"node17\" class=\"node\">\n<title>5086100784</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2443,-112.5 2443,-148.5 2625,-148.5 2625,-112.5 2443,-112.5\"/>\n<text text-anchor=\"middle\" x=\"2453\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2463,-112.5 2463,-148.5 \"/>\n<text text-anchor=\"middle\" x=\"2503\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.1464</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2543,-112.5 2543,-148.5 \"/>\n<text text-anchor=\"middle\" x=\"2584\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 4.8284</text>\n</g>\n<!-- 5086100784&#45;&gt;5086086096* -->\n<g id=\"edge13\" class=\"edge\">\n<title>5086100784&#45;&gt;5086086096*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2625.18,-144.15C2634.42,-145.54 2643.38,-146.9 2651.47,-148.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2651.15,-151.61 2661.56,-149.65 2652.19,-144.69 2651.15,-151.61\"/>\n</g>\n<!-- 5086100784**&#45;1 -->\n<g id=\"node18\" class=\"node\">\n<title>5086100784**&#45;1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2316\" cy=\"-126.5\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2316\" y=\"-122.8\" font-family=\"Times,serif\" font-size=\"14.00\">**&#45;1</text>\n</g>\n<!-- 5086100784**&#45;1&#45;&gt;5086100784 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5086100784**&#45;1&#45;&gt;5086100784</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2343.05,-126.98C2365.53,-127.4 2399.48,-128.03 2432.5,-128.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2432.64,-132.14 2442.7,-128.83 2432.77,-125.14 2432.64,-132.14\"/>\n</g>\n<!-- 5086086960 -->\n<g id=\"node19\" class=\"node\">\n<title>5086086960</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2003,-108.5 2003,-144.5 2189,-144.5 2189,-108.5 2003,-108.5\"/>\n<text text-anchor=\"middle\" x=\"2013\" y=\"-122.8\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2023,-108.5 2023,-144.5 \"/>\n<text text-anchor=\"middle\" x=\"2063\" y=\"-122.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 6.8284</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2103,-108.5 2103,-144.5 \"/>\n<text text-anchor=\"middle\" x=\"2146\" y=\"-122.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;0.1036</text>\n</g>\n<!-- 5086086960&#45;&gt;5086100784**&#45;1 -->\n<g id=\"edge19\" class=\"edge\">\n<title>5086086960&#45;&gt;5086100784**&#45;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2189.14,-126.5C2220.72,-126.5 2254.24,-126.5 2278.74,-126.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2278.98,-130 2288.98,-126.5 2278.98,-123 2278.98,-130\"/>\n</g>\n<!-- 5086086960+&#45;&gt;5086086960 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5086086960+&#45;&gt;5086086960</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1967.12,-126.5C1974.62,-126.5 1983.29,-126.5 1992.5,-126.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1992.69,-130 2002.69,-126.5 1992.69,-123 1992.69,-130\"/>\n</g>\n<!-- 5086100352 -->\n<g id=\"node21\" class=\"node\">\n<title>5086100352</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2.5,-110.5 2.5,-146.5 197.5,-146.5 197.5,-110.5 2.5,-110.5\"/>\n<text text-anchor=\"middle\" x=\"19\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"35.5,-110.5 35.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"75.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 1.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"115.5,-110.5 115.5,-146.5 \"/>\n<text text-anchor=\"middle\" x=\"156.5\" y=\"-124.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.0000</text>\n</g>\n<!-- 5086100352&#45;&gt;5086097712* -->\n<g id=\"edge18\" class=\"edge\">\n<title>5086100352&#45;&gt;5086097712*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M197.91,-128.5C207.65,-128.5 217.05,-128.5 225.52,-128.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"225.7,-132 235.7,-128.5 225.7,-125 225.7,-132\"/>\n</g>\n<!-- 5086089648 -->\n<g id=\"node22\" class=\"node\">\n<title>5086089648</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2,-0.5 2,-36.5 198,-36.5 198,-0.5 2,-0.5\"/>\n<text text-anchor=\"middle\" x=\"17\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"32,-0.5 32,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 2.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"112,-0.5 112,-36.5 \"/>\n<text text-anchor=\"middle\" x=\"155\" y=\"-14.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad &#45;1.5000</text>\n</g>\n<!-- 5086089648&#45;&gt;5086100448* -->\n<g id=\"edge27\" class=\"edge\">\n<title>5086089648&#45;&gt;5086100448*</title>\n<path fill=\"none\" stroke=\"black\" d=\"M172.53,-36.56C181.84,-39.33 191.2,-42.33 200,-45.5 210.53,-49.29 221.75,-54.1 231.72,-58.67\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"230.28,-61.86 240.82,-62.93 233.25,-55.52 230.28,-61.86\"/>\n</g>\n<!-- 5086085568 -->\n<g id=\"node23\" class=\"node\">\n<title>5086085568</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"672,-82.5 672,-118.5 945,-118.5 945,-82.5 672,-82.5\"/>\n<text text-anchor=\"middle\" x=\"725\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1*w1 + x2*w2</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"778,-82.5 778,-118.5 \"/>\n<text text-anchor=\"middle\" x=\"820.5\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"863,-82.5 863,-118.5 \"/>\n<text text-anchor=\"middle\" x=\"904\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086085568&#45;&gt;5086098000+ -->\n<g id=\"edge25\" class=\"edge\">\n<title>5086085568&#45;&gt;5086098000+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M941.24,-118.51C952.12,-120 962.4,-121.4 971.45,-122.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"971.11,-126.13 981.49,-124.01 972.05,-119.19 971.11,-126.13\"/>\n</g>\n<!-- 5086085568+&#45;&gt;5086085568 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5086085568+&#45;&gt;5086085568</title>\n<path fill=\"none\" stroke=\"black\" d=\"M636.23,-100.5C643.7,-100.5 652.41,-100.5 661.87,-100.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"661.98,-104 671.98,-100.5 661.98,-97 661.98,-104\"/>\n</g>\n<!-- 5086086096 -->\n<g id=\"node25\" class=\"node\">\n<title>5086086096</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"2751,-135.5 2751,-171.5 2936,-171.5 2936,-135.5 2751,-135.5\"/>\n<text text-anchor=\"middle\" x=\"2762.5\" y=\"-149.8\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2774,-135.5 2774,-171.5 \"/>\n<text text-anchor=\"middle\" x=\"2814\" y=\"-149.8\" font-family=\"Times,serif\" font-size=\"14.00\">data 0.7071</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"2854,-135.5 2854,-171.5 \"/>\n<text text-anchor=\"middle\" x=\"2895\" y=\"-149.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 1.0000</text>\n</g>\n<!-- 5086086096*&#45;&gt;5086086096 -->\n<g id=\"edge9\" class=\"edge\">\n<title>5086086096*&#45;&gt;5086086096</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2715.04,-153.5C2722.58,-153.5 2731.3,-153.5 2740.57,-153.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2740.81,-157 2750.81,-153.5 2740.81,-150 2740.81,-157\"/>\n</g>\n<!-- 5086100448 -->\n<g id=\"node27\" class=\"node\">\n<title>5086100448</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"326,-55.5 326,-91.5 546,-91.5 546,-55.5 326,-55.5\"/>\n<text text-anchor=\"middle\" x=\"352.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">x1*w1</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"379,-55.5 379,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"421.5\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n<polyline fill=\"none\" stroke=\"black\" points=\"464,-55.5 464,-91.5 \"/>\n<text text-anchor=\"middle\" x=\"505\" y=\"-69.8\" font-family=\"Times,serif\" font-size=\"14.00\">grad 0.5000</text>\n</g>\n<!-- 5086100448&#45;&gt;5086085568+ -->\n<g id=\"edge14\" class=\"edge\">\n<title>5086100448&#45;&gt;5086085568+</title>\n<path fill=\"none\" stroke=\"black\" d=\"M546.27,-90.75C555.64,-92.23 564.6,-93.65 572.65,-94.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"572.23,-98.4 582.65,-96.5 573.32,-91.48 572.23,-98.4\"/>\n</g>\n<!-- 5086100448*&#45;&gt;5086100448 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5086100448*&#45;&gt;5086100448</title>\n<path fill=\"none\" stroke=\"black\" d=\"M290.34,-73.5C297.77,-73.5 306.37,-73.5 315.6,-73.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"315.84,-77 325.84,-73.5 315.84,-70 315.84,-77\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12f27a200>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs x1,x2\n",
    "x1 = Value(2.0, label='x1')\n",
    "x2 = Value(0.0, label='x2')\n",
    "# weights w1,w2\n",
    "w1 = Value(-3.0, label='w1')\n",
    "w2 = Value(1.0, label='w2')\n",
    "# bias of the neuron\n",
    "b = Value(6.8813735870195432, label='b')\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
    "x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "n = x1w1x2w2 + b; n.label = 'n'\n",
    "e = (2*n).exp()\n",
    "o = (e - 1) / (e + 1)\n",
    "o.label = 'o'\n",
    "o.backward()\n",
    "draw_dot(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071066904050358\n",
      "---\n",
      "x2 0.5000001283844369\n",
      "w2 0.0\n",
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.Tensor([2.0]).double(); x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double(); x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double(); w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double(); w2.requires_grad = True\n",
    "b = torch.Tensor([6.8813735870195432]).double(); b.requires_grad = True\n",
    "n = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "print('---')\n",
    "print('x2', x2.grad.item())\n",
    "print('w2', w2.grad.item())\n",
    "print('x1', x1.grad.item())\n",
    "print('w1', w1.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1, 1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        act = sum((wi * xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-0.8085136328066914)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2.0, 3.0, -1.0]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step= 0 ; loss =  6.6312526809538515\n",
      "step= 1 ; loss =  5.059058550525371\n",
      "step= 2 ; loss =  3.1922112458161145\n",
      "step= 3 ; loss =  2.4622305957046886\n",
      "step= 4 ; loss =  1.6334222919240555\n",
      "step= 5 ; loss =  0.9969290553195342\n",
      "step= 6 ; loss =  0.5598711399171279\n",
      "step= 7 ; loss =  0.3011657012892376\n",
      "step= 8 ; loss =  0.20297520827484308\n",
      "step= 9 ; loss =  0.16888235932113604\n",
      "step= 10 ; loss =  0.14460661128309057\n",
      "step= 11 ; loss =  0.1262826334926468\n",
      "step= 12 ; loss =  0.11196137586720938\n",
      "step= 13 ; loss =  0.10046753255804351\n",
      "step= 14 ; loss =  0.09104482103107434\n",
      "step= 15 ; loss =  0.08318408022041546\n",
      "step= 16 ; loss =  0.07652996558688917\n",
      "step= 17 ; loss =  0.07082699207608216\n",
      "step= 18 ; loss =  0.06588680030937182\n",
      "step= 19 ; loss =  0.06156750133257155\n",
      "step= 20 ; loss =  0.05776020150219232\n",
      "step= 21 ; loss =  0.054379955697001034\n",
      "step= 22 ; loss =  0.05135953978018969\n",
      "step= 23 ; loss =  0.04864506837369501\n",
      "step= 24 ; loss =  0.04619285036369125\n",
      "step= 25 ; loss =  0.043967092853248485\n",
      "step= 26 ; loss =  0.04193819814371723\n",
      "step= 27 ; loss =  0.04008148254782837\n",
      "step= 28 ; loss =  0.038376200059596285\n",
      "step= 29 ; loss =  0.03680478954842892\n",
      "step= 30 ; loss =  0.035352288020902824\n",
      "step= 31 ; loss =  0.03400586876592741\n",
      "step= 32 ; loss =  0.0327544744656955\n",
      "step= 33 ; loss =  0.03158852326988842\n",
      "step= 34 ; loss =  0.030499671466197555\n",
      "step= 35 ; loss =  0.02948062044296049\n",
      "step= 36 ; loss =  0.02852495860253274\n",
      "step= 37 ; loss =  0.027627031068047023\n",
      "step= 38 ; loss =  0.026781831652375066\n",
      "step= 39 ; loss =  0.02598491278031026\n",
      "step= 40 ; loss =  0.025232309981706842\n",
      "step= 41 ; loss =  0.024520478281798905\n",
      "step= 42 ; loss =  0.023846238360817507\n",
      "step= 43 ; loss =  0.02320673077872688\n",
      "step= 44 ; loss =  0.022599376892058806\n",
      "step= 45 ; loss =  0.02202184535034967\n",
      "step= 46 ; loss =  0.02147202326592798\n",
      "step= 47 ; loss =  0.020947991315027746\n",
      "step= 48 ; loss =  0.0204480021597218\n",
      "step= 49 ; loss =  0.019970461686047374\n",
      "step= 50 ; loss =  0.01951391263937289\n",
      "step= 51 ; loss =  0.019077020307719534\n",
      "step= 52 ; loss =  0.01865855996065996\n",
      "step= 53 ; loss =  0.018257405798109534\n",
      "step= 54 ; loss =  0.01787252120180369\n",
      "step= 55 ; loss =  0.017502950114085744\n",
      "step= 56 ; loss =  0.017147809395071247\n",
      "step= 57 ; loss =  0.016806282031296183\n",
      "step= 58 ; loss =  0.01647761108739906\n",
      "step= 59 ; loss =  0.01616109430787021\n",
      "step= 60 ; loss =  0.015856079288944676\n",
      "step= 61 ; loss =  0.015561959151735104\n",
      "step= 62 ; loss =  0.015278168657045585\n",
      "step= 63 ; loss =  0.01500418071024662\n",
      "step= 64 ; loss =  0.014739503211366503\n",
      "step= 65 ; loss =  0.014483676211340534\n",
      "step= 66 ; loss =  0.014236269340324424\n",
      "step= 67 ; loss =  0.013996879478242146\n",
      "step= 68 ; loss =  0.013765128641414173\n",
      "step= 69 ; loss =  0.01354066206228444\n",
      "step= 70 ; loss =  0.013323146442013902\n",
      "step= 71 ; loss =  0.013112268358089365\n",
      "step= 72 ; loss =  0.01290773281117227\n",
      "step= 73 ; loss =  0.012709261897215041\n",
      "step= 74 ; loss =  0.012516593592452305\n",
      "step= 75 ; loss =  0.012329480640252088\n",
      "step= 76 ; loss =  0.012147689530022777\n",
      "step= 77 ; loss =  0.011970999559434023\n",
      "step= 78 ; loss =  0.011799201972142943\n",
      "step= 79 ; loss =  0.011632099164043121\n",
      "step= 80 ; loss =  0.011469503951779165\n",
      "step= 81 ; loss =  0.011311238897914818\n",
      "step= 82 ; loss =  0.011157135687711019\n",
      "step= 83 ; loss =  0.011007034552977486\n",
      "step= 84 ; loss =  0.010860783738909582\n",
      "step= 85 ; loss =  0.010718239010223358\n",
      "step= 86 ; loss =  0.010579263193257698\n",
      "step= 87 ; loss =  0.010443725751030652\n",
      "step= 88 ; loss =  0.010311502388522062\n",
      "step= 89 ; loss =  0.010182474685708851\n",
      "step= 90 ; loss =  0.010056529756108115\n",
      "step= 91 ; loss =  0.009933559928787021\n",
      "step= 92 ; loss =  0.009813462451984336\n",
      "step= 93 ; loss =  0.009696139216651937\n",
      "step= 94 ; loss =  0.009581496498375926\n",
      "step= 95 ; loss =  0.009469444716269928\n",
      "step= 96 ; loss =  0.009359898207555733\n",
      "step= 97 ; loss =  0.009252775016655777\n",
      "step= 98 ; loss =  0.009147996697721587\n",
      "step= 99 ; loss =  0.009045488129612082\n",
      "step= 100 ; loss =  0.008945177342417985\n",
      "step= 101 ; loss =  0.008846995354701702\n",
      "step= 102 ; loss =  0.00875087602069061\n",
      "step= 103 ; loss =  0.00865675588672175\n",
      "step= 104 ; loss =  0.00856457405629324\n",
      "step= 105 ; loss =  0.008474272063126965\n",
      "step= 106 ; loss =  0.008385793751694683\n",
      "step= 107 ; loss =  0.008299085164701746\n",
      "step= 108 ; loss =  0.00821409443706134\n",
      "step= 109 ; loss =  0.008130771695927262\n",
      "step= 110 ; loss =  0.008049068966386741\n",
      "step= 111 ; loss =  0.00796894008244264\n",
      "step= 112 ; loss =  0.00789034060294441\n",
      "step= 113 ; loss =  0.007813227732148846\n",
      "step= 114 ; loss =  0.007737560244618261\n",
      "step= 115 ; loss =  0.007663298414181119\n",
      "step= 116 ; loss =  0.007590403946703285\n",
      "step= 117 ; loss =  0.007518839916432875\n",
      "step= 118 ; loss =  0.007448570705700207\n",
      "step= 119 ; loss =  0.007379561947768315\n",
      "step= 120 ; loss =  0.007311780472644657\n",
      "step= 121 ; loss =  0.007245194255676319\n",
      "step= 122 ; loss =  0.007179772368764248\n",
      "step= 123 ; loss =  0.007115484934041981\n",
      "step= 124 ; loss =  0.007052303079875636\n",
      "step= 125 ; loss =  0.006990198899050785\n",
      "step= 126 ; loss =  0.006929145409020121\n",
      "step= 127 ; loss =  0.006869116514095859\n",
      "step= 128 ; loss =  0.006810086969475724\n",
      "step= 129 ; loss =  0.006752032347000881\n",
      "step= 130 ; loss =  0.006694929002548757\n",
      "step= 131 ; loss =  0.0066387540449712006\n",
      "step= 132 ; loss =  0.006583485306493015\n",
      "step= 133 ; loss =  0.00652910131449172\n",
      "step= 134 ; loss =  0.006475581264584081\n",
      "step= 135 ; loss =  0.006422904994949558\n",
      "step= 136 ; loss =  0.006371052961824833\n",
      "step= 137 ; loss =  0.006320006216107923\n",
      "step= 138 ; loss =  0.0062697463810137966\n",
      "step= 139 ; loss =  0.006220255630726677\n",
      "step= 140 ; loss =  0.006171516669998074\n",
      "step= 141 ; loss =  0.006123512714641567\n",
      "step= 142 ; loss =  0.006076227472879557\n",
      "step= 143 ; loss =  0.006029645127498016\n",
      "step= 144 ; loss =  0.005983750318769833\n",
      "step= 145 ; loss =  0.005938528128107537\n",
      "step= 146 ; loss =  0.0058939640624102755\n",
      "step= 147 ; loss =  0.00585004403907001\n",
      "step= 148 ; loss =  0.005806754371605896\n",
      "step= 149 ; loss =  0.005764081755895475\n",
      "step= 150 ; loss =  0.005722013256974601\n",
      "step= 151 ; loss =  0.0056805362963787374\n",
      "step= 152 ; loss =  0.005639638640000084\n",
      "step= 153 ; loss =  0.005599308386435947\n",
      "step= 154 ; loss =  0.0055595339558056804\n",
      "step= 155 ; loss =  0.005520304079014269\n",
      "step= 156 ; loss =  0.0054816077874419635\n",
      "step= 157 ; loss =  0.005443434403040387\n",
      "step= 158 ; loss =  0.005405773528816606\n",
      "step= 159 ; loss =  0.00536861503968755\n",
      "step= 160 ; loss =  0.0053319490736881475\n",
      "step= 161 ; loss =  0.005295766023517438\n",
      "step= 162 ; loss =  0.005260056528407409\n",
      "step= 163 ; loss =  0.005224811466300487\n",
      "step= 164 ; loss =  0.005190021946322241\n",
      "step= 165 ; loss =  0.005155679301535904\n",
      "step= 166 ; loss =  0.005121775081967291\n",
      "step= 167 ; loss =  0.005088301047887667\n",
      "step= 168 ; loss =  0.005055249163344062\n",
      "step= 169 ; loss =  0.005022611589926205\n",
      "step= 170 ; loss =  0.004990380680760174\n",
      "step= 171 ; loss =  0.00495854897471925\n",
      "step= 172 ; loss =  0.004927109190842744\n",
      "step= 173 ; loss =  0.004896054222954349\n",
      "step= 174 ; loss =  0.004865377134471649\n",
      "step= 175 ; loss =  0.00483507115339877\n",
      "step= 176 ; loss =  0.004805129667495151\n",
      "step= 177 ; loss =  0.004775546219612738\n",
      "step= 178 ; loss =  0.0047463145031950964\n",
      "step= 179 ; loss =  0.004717428357932135\n",
      "step= 180 ; loss =  0.004688881765563448\n",
      "step= 181 ; loss =  0.004660668845825466\n",
      "step= 182 ; loss =  0.004632783852535829\n",
      "step= 183 ; loss =  0.004605221169809939\n",
      "step= 184 ; loss =  0.004577975308404698\n",
      "step= 185 ; loss =  0.004551040902184089\n",
      "step= 186 ; loss =  0.004524412704702319\n",
      "step= 187 ; loss =  0.004498085585899596\n",
      "step= 188 ; loss =  0.00447205452890659\n",
      "step= 189 ; loss =  0.004446314626953151\n",
      "step= 190 ; loss =  0.004420861080377649\n",
      "step= 191 ; loss =  0.00439568919373284\n",
      "step= 192 ; loss =  0.004370794372984784\n",
      "step= 193 ; loss =  0.004346172122801462\n",
      "step= 194 ; loss =  0.004321818043927572\n",
      "step= 195 ; loss =  0.004297727830642434\n",
      "step= 196 ; loss =  0.004273897268297949\n",
      "step= 197 ; loss =  0.004250322230933664\n",
      "step= 198 ; loss =  0.004226998678966301\n",
      "step= 199 ; loss =  0.004203922656950574\n",
      "step= 200 ; loss =  0.004181090291409636\n",
      "step= 201 ; loss =  0.004158497788731555\n",
      "step= 202 ; loss =  0.004136141433130401\n",
      "step= 203 ; loss =  0.0041140175846691995\n",
      "step= 204 ; loss =  0.004092122677342721\n",
      "step= 205 ; loss =  0.004070453217217675\n",
      "step= 206 ; loss =  0.004049005780629074\n",
      "step= 207 ; loss =  0.0040277770124299015\n",
      "step= 208 ; loss =  0.004006763624292969\n",
      "step= 209 ; loss =  0.003985962393062676\n",
      "step= 210 ; loss =  0.0039653701591553115\n",
      "step= 211 ; loss =  0.003944983825006044\n",
      "step= 212 ; loss =  0.0039248003535611396\n",
      "step= 213 ; loss =  0.003904816766813654\n",
      "step= 214 ; loss =  0.0038850301443816445\n",
      "step= 215 ; loss =  0.0038654376221266863\n",
      "step= 216 ; loss =  0.0038460363908123666\n",
      "step= 217 ; loss =  0.003826823694800324\n",
      "step= 218 ; loss =  0.003807796830783661\n",
      "step= 219 ; loss =  0.003788953146555578\n",
      "step= 220 ; loss =  0.0037702900398128908\n",
      "step= 221 ; loss =  0.0037518049569925534\n",
      "step= 222 ; loss =  0.0037334953921408466\n",
      "step= 223 ; loss =  0.003715358885813427\n",
      "step= 224 ; loss =  0.003697393024005982\n",
      "step= 225 ; loss =  0.0036795954371139717\n",
      "step= 226 ; loss =  0.003661963798920781\n",
      "step= 227 ; loss =  0.003644495825613292\n",
      "step= 228 ; loss =  0.0036271892748242504\n",
      "step= 229 ; loss =  0.0036100419447000777\n",
      "step= 230 ; loss =  0.0035930516729939964\n",
      "step= 231 ; loss =  0.003576216336182984\n",
      "step= 232 ; loss =  0.0035595338486085334\n",
      "step= 233 ; loss =  0.0035430021616398607\n",
      "step= 234 ; loss =  0.0035266192628592226\n",
      "step= 235 ; loss =  0.0035103831752686466\n",
      "step= 236 ; loss =  0.0034942919565172864\n",
      "step= 237 ; loss =  0.003478343698148879\n",
      "step= 238 ; loss =  0.0034625365248687123\n",
      "step= 239 ; loss =  0.0034468685938293777\n",
      "step= 240 ; loss =  0.0034313380939349895\n",
      "step= 241 ; loss =  0.0034159432451630416\n",
      "step= 242 ; loss =  0.003400682297903657\n",
      "step= 243 ; loss =  0.003385553532315447\n",
      "step= 244 ; loss =  0.003370555257697691\n",
      "step= 245 ; loss =  0.0033556858118783273\n",
      "step= 246 ; loss =  0.0033409435606171914\n",
      "step= 247 ; loss =  0.0033263268970241127\n",
      "step= 248 ; loss =  0.0033118342409916017\n",
      "step= 249 ; loss =  0.0032974640386413435\n",
      "step= 250 ; loss =  0.0032832147617845257\n",
      "step= 251 ; loss =  0.0032690849073952356\n",
      "step= 252 ; loss =  0.0032550729970968325\n",
      "step= 253 ; loss =  0.003241177576660737\n",
      "step= 254 ; loss =  0.003227397215517491\n",
      "step= 255 ; loss =  0.0032137305062793897\n",
      "step= 256 ; loss =  0.003200176064274858\n",
      "step= 257 ; loss =  0.0031867325270936993\n",
      "step= 258 ; loss =  0.003173398554143529\n",
      "step= 259 ; loss =  0.0031601728262163533\n",
      "step= 260 ; loss =  0.003147054045065785\n",
      "step= 261 ; loss =  0.003134040932993827\n",
      "step= 262 ; loss =  0.0031211322324478505\n",
      "step= 263 ; loss =  0.003108326705626461\n",
      "step= 264 ; loss =  0.0030956231340950073\n",
      "step= 265 ; loss =  0.0030830203184097093\n",
      "step= 266 ; loss =  0.003070517077750662\n",
      "step= 267 ; loss =  0.003058112249563206\n",
      "step= 268 ; loss =  0.003045804689207515\n",
      "step= 269 ; loss =  0.003033593269616273\n",
      "step= 270 ; loss =  0.003021476880960074\n",
      "step= 271 ; loss =  0.0030094544303205083\n",
      "step= 272 ; loss =  0.0029975248413705038\n",
      "step= 273 ; loss =  0.002985687054061965\n",
      "step= 274 ; loss =  0.002973940024320461\n",
      "step= 275 ; loss =  0.0029622827237466083\n",
      "step= 276 ; loss =  0.002950714139324224\n",
      "step= 277 ; loss =  0.002939233273134904\n",
      "step= 278 ; loss =  0.0029278391420789144\n",
      "step= 279 ; loss =  0.0029165307776022626\n",
      "step= 280 ; loss =  0.002905307225429784\n",
      "step= 281 ; loss =  0.002894167545303921\n",
      "step= 282 ; loss =  0.0028831108107294293\n",
      "step= 283 ; loss =  0.002872136108723398\n",
      "step= 284 ; loss =  0.0028612425395708515\n",
      "step= 285 ; loss =  0.002850429216585612\n",
      "step= 286 ; loss =  0.0028396952658760973\n",
      "step= 287 ; loss =  0.002829039826116447\n",
      "step= 288 ; loss =  0.0028184620483223156\n",
      "step= 289 ; loss =  0.0028079610956314558\n",
      "step= 290 ; loss =  0.0027975361430890434\n",
      "step= 291 ; loss =  0.0027871863774374898\n",
      "step= 292 ; loss =  0.0027769109969106127\n",
      "step= 293 ; loss =  0.002766709211032294\n",
      "step= 294 ; loss =  0.002756580240419052\n",
      "step= 295 ; loss =  0.002746523316587196\n",
      "step= 296 ; loss =  0.002736537681763385\n",
      "step= 297 ; loss =  0.0027266225886996543\n",
      "step= 298 ; loss =  0.0027167773004919357\n",
      "step= 299 ; loss =  0.002707001090402384\n",
      "step= 300 ; loss =  0.002697293241685373\n",
      "step= 301 ; loss =  0.002687653047417057\n",
      "step= 302 ; loss =  0.0026780798103283408\n",
      "step= 303 ; loss =  0.002668572842641211\n",
      "step= 304 ; loss =  0.0026591314659085673\n",
      "step= 305 ; loss =  0.0026497550108569522\n",
      "step= 306 ; loss =  0.0026404428172328454\n",
      "step= 307 ; loss =  0.0026311942336516023\n",
      "step= 308 ; loss =  0.0026220086174497887\n",
      "step= 309 ; loss =  0.002612885334540199\n",
      "step= 310 ; loss =  0.002603823759269814\n",
      "step= 311 ; loss =  0.0025948232742806676\n",
      "step= 312 ; loss =  0.0025858832703732583\n",
      "step= 313 ; loss =  0.002577003146372847\n",
      "step= 314 ; loss =  0.002568182308998214\n",
      "step= 315 ; loss =  0.002559420172733008\n",
      "step= 316 ; loss =  0.002550716159699718\n",
      "step= 317 ; loss =  0.002542069699535924\n",
      "step= 318 ; loss =  0.00253348022927297\n",
      "step= 319 ; loss =  0.0025249471932170995\n",
      "step= 320 ; loss =  0.0025164700428327007\n",
      "step= 321 ; loss =  0.0025080482366278837\n",
      "step= 322 ; loss =  0.002499681240042273\n",
      "step= 323 ; loss =  0.0024913685253367774\n",
      "step= 324 ; loss =  0.0024831095714856672\n",
      "step= 325 ; loss =  0.0024749038640704633\n",
      "step= 326 ; loss =  0.0024667508951760654\n",
      "step= 327 ; loss =  0.0024586501632885647\n",
      "step= 328 ; loss =  0.0024506011731951975\n",
      "step= 329 ; loss =  0.002442603435886043\n",
      "step= 330 ; loss =  0.0024346564684576176\n",
      "step= 331 ; loss =  0.0024267597940181695\n",
      "step= 332 ; loss =  0.0024189129415948174\n",
      "step= 333 ; loss =  0.0024111154460423044\n",
      "step= 334 ; loss =  0.00240336684795362\n",
      "step= 335 ; loss =  0.0023956666935719636\n",
      "step= 336 ; loss =  0.002388014534704557\n",
      "step= 337 ; loss =  0.00238040992863796\n",
      "step= 338 ; loss =  0.002372852438054893\n",
      "step= 339 ; loss =  0.002365341630952601\n",
      "step= 340 ; loss =  0.002357877080562624\n",
      "step= 341 ; loss =  0.002350458365272135\n",
      "step= 342 ; loss =  0.0023430850685465755\n",
      "step= 343 ; loss =  0.0023357567788537333\n",
      "step= 344 ; loss =  0.002328473089589161\n",
      "step= 345 ; loss =  0.002321233599002885\n",
      "step= 346 ; loss =  0.0023140379101275\n",
      "step= 347 ; loss =  0.0023068856307074774\n",
      "step= 348 ; loss =  0.002299776373129681\n",
      "step= 349 ; loss =  0.002292709754355208\n",
      "step= 350 ; loss =  0.002285685395852331\n",
      "step= 351 ; loss =  0.0022787029235306847\n",
      "step= 352 ; loss =  0.002271761967676521\n",
      "step= 353 ; loss =  0.0022648621628891695\n",
      "step= 354 ; loss =  0.0022580031480185243\n",
      "step= 355 ; loss =  0.0022511845661037193\n",
      "step= 356 ; loss =  0.0022444060643127353\n",
      "step= 357 ; loss =  0.0022376672938830954\n",
      "step= 358 ; loss =  0.0022309679100636377\n",
      "step= 359 ; loss =  0.002224307572057138\n",
      "step= 360 ; loss =  0.0022176859429641287\n",
      "step= 361 ; loss =  0.002211102689727411\n",
      "step= 362 ; loss =  0.002204557483077751\n",
      "step= 363 ; loss =  0.002198049997480321\n",
      "step= 364 ; loss =  0.002191579911082089\n",
      "step= 365 ; loss =  0.0021851469056601803\n",
      "step= 366 ; loss =  0.002178750666570985\n",
      "step= 367 ; loss =  0.0021723908827001974\n",
      "step= 368 ; loss =  0.0021660672464135656\n",
      "step= 369 ; loss =  0.0021597794535086986\n",
      "step= 370 ; loss =  0.0021535272031673863\n",
      "step= 371 ; loss =  0.002147310197908956\n",
      "step= 372 ; loss =  0.002141128143544187\n",
      "step= 373 ; loss =  0.0021349807491301376\n",
      "step= 374 ; loss =  0.002128867726925707\n",
      "step= 375 ; loss =  0.002122788792347747\n",
      "step= 376 ; loss =  0.0021167436639281372\n",
      "step= 377 ; loss =  0.0021107320632713813\n",
      "step= 378 ; loss =  0.002104753715012995\n",
      "step= 379 ; loss =  0.0020988083467784508\n",
      "step= 380 ; loss =  0.0020928956891429007\n",
      "step= 381 ; loss =  0.002087015475591545\n",
      "step= 382 ; loss =  0.0020811674424805107\n",
      "step= 383 ; loss =  0.002075351328998487\n",
      "step= 384 ; loss =  0.0020695668771289442\n",
      "step= 385 ; loss =  0.002063813831612874\n",
      "step= 386 ; loss =  0.0020580919399122675\n",
      "step= 387 ; loss =  0.002052400952174051\n",
      "step= 388 ; loss =  0.002046740621194614\n",
      "step= 389 ; loss =  0.0020411107023849294\n",
      "step= 390 ; loss =  0.0020355109537362184\n",
      "step= 391 ; loss =  0.002029941135786098\n",
      "step= 392 ; loss =  0.002024401011585382\n",
      "step= 393 ; loss =  0.0020188903466652483\n",
      "step= 394 ; loss =  0.0020134089090049784\n",
      "step= 395 ; loss =  0.0020079564690002618\n",
      "step= 396 ; loss =  0.00200253279943196\n",
      "step= 397 ; loss =  0.001997137675435182\n",
      "step= 398 ; loss =  0.0019917708744691827\n",
      "step= 399 ; loss =  0.001986432176287337\n",
      "step= 400 ; loss =  0.0019811213629079404\n",
      "step= 401 ; loss =  0.0019758382185851193\n",
      "step= 402 ; loss =  0.001970582529780431\n",
      "step= 403 ; loss =  0.00196535408513481\n",
      "step= 404 ; loss =  0.0019601526754408857\n",
      "step= 405 ; loss =  0.0019549780936158044\n",
      "step= 406 ; loss =  0.001949830134674447\n",
      "step= 407 ; loss =  0.0019447085957029816\n",
      "step= 408 ; loss =  0.0019396132758329255\n",
      "step= 409 ; loss =  0.0019345439762154422\n",
      "step= 410 ; loss =  0.00192950049999625\n",
      "step= 411 ; loss =  0.001924482652290596\n",
      "step= 412 ; loss =  0.001919490240158959\n",
      "step= 413 ; loss =  0.0019145230725827749\n",
      "step= 414 ; loss =  0.0019095809604407498\n",
      "step= 415 ; loss =  0.0019046637164854873\n",
      "step= 416 ; loss =  0.0018997711553203074\n",
      "step= 417 ; loss =  0.0018949030933766266\n",
      "step= 418 ; loss =  0.0018900593488914972\n",
      "step= 419 ; loss =  0.0018852397418856158\n",
      "step= 420 ; loss =  0.0018804440941414479\n",
      "step= 421 ; loss =  0.0018756722291819645\n",
      "step= 422 ; loss =  0.001870923972249389\n",
      "step= 423 ; loss =  0.001866199150284469\n",
      "step= 424 ; loss =  0.0018614975919059216\n",
      "step= 425 ; loss =  0.0018568191273902292\n",
      "step= 426 ; loss =  0.0018521635886517866\n",
      "step= 427 ; loss =  0.0018475308092230735\n",
      "step= 428 ; loss =  0.0018429206242355305\n",
      "step= 429 ; loss =  0.0018383328704003597\n",
      "step= 430 ; loss =  0.001833767385989685\n",
      "step= 431 ; loss =  0.0018292240108180621\n",
      "step= 432 ; loss =  0.0018247025862242366\n",
      "step= 433 ; loss =  0.0018202029550530563\n",
      "step= 434 ; loss =  0.0018157249616376832\n",
      "step= 435 ; loss =  0.0018112684517822282\n",
      "step= 436 ; loss =  0.0018068332727443097\n",
      "step= 437 ; loss =  0.0018024192732181154\n",
      "step= 438 ; loss =  0.0017980263033176122\n",
      "step= 439 ; loss =  0.0017936542145599614\n",
      "step= 440 ; loss =  0.001789302859849218\n",
      "step= 441 ; loss =  0.0017849720934602405\n",
      "step= 442 ; loss =  0.0017806617710227832\n",
      "step= 443 ; loss =  0.0017763717495058876\n",
      "step= 444 ; loss =  0.0017721018872024108\n",
      "step= 445 ; loss =  0.0017678520437137946\n",
      "step= 446 ; loss =  0.0017636220799350805\n",
      "step= 447 ; loss =  0.0017594118580400958\n",
      "step= 448 ; loss =  0.0017552212414667953\n",
      "step= 449 ; loss =  0.0017510500949029421\n",
      "step= 450 ; loss =  0.001746898284271793\n",
      "step= 451 ; loss =  0.0017427656767181501\n",
      "step= 452 ; loss =  0.001738652140594517\n",
      "step= 453 ; loss =  0.0017345575454474206\n",
      "step= 454 ; loss =  0.0017304817620040235\n",
      "step= 455 ; loss =  0.0017264246621587537\n",
      "step= 456 ; loss =  0.001722386118960265\n",
      "step= 457 ; loss =  0.001718366006598564\n",
      "step= 458 ; loss =  0.0017143642003921028\n",
      "step= 459 ; loss =  0.0017103805767753626\n",
      "step= 460 ; loss =  0.001706415013286347\n",
      "step= 461 ; loss =  0.0017024673885543521\n",
      "step= 462 ; loss =  0.0016985375822879064\n",
      "step= 463 ; loss =  0.0016946254752628156\n",
      "step= 464 ; loss =  0.0016907309493103847\n",
      "step= 465 ; loss =  0.0016868538873058688\n",
      "step= 466 ; loss =  0.0016829941731569085\n",
      "step= 467 ; loss =  0.0016791516917923203\n",
      "step= 468 ; loss =  0.001675326329150862\n",
      "step= 469 ; loss =  0.0016715179721702791\n",
      "step= 470 ; loss =  0.0016677265087763535\n",
      "step= 471 ; loss =  0.0016639518278722485\n",
      "step= 472 ; loss =  0.0016601938193278672\n",
      "step= 473 ; loss =  0.0016564523739694068\n",
      "step= 474 ; loss =  0.0016527273835690351\n",
      "step= 475 ; loss =  0.0016490187408347587\n",
      "step= 476 ; loss =  0.0016453263394002305\n",
      "step= 477 ; loss =  0.0016416500738149872\n",
      "step= 478 ; loss =  0.0016379898395345472\n",
      "step= 479 ; loss =  0.0016343455329107346\n",
      "step= 480 ; loss =  0.0016307170511821792\n",
      "step= 481 ; loss =  0.0016271042924648669\n",
      "step= 482 ; loss =  0.0016235071557427734\n",
      "step= 483 ; loss =  0.0016199255408587709\n",
      "step= 484 ; loss =  0.0016163593485054835\n",
      "step= 485 ; loss =  0.0016128084802163238\n",
      "step= 486 ; loss =  0.0016092728383566978\n",
      "step= 487 ; loss =  0.0016057523261152175\n",
      "step= 488 ; loss =  0.0016022468474950857\n",
      "step= 489 ; loss =  0.0015987563073055764\n",
      "step= 490 ; loss =  0.0015952806111536404\n",
      "step= 491 ; loss =  0.001591819665435557\n",
      "step= 492 ; loss =  0.0015883733773287938\n",
      "step= 493 ; loss =  0.0015849416547838223\n",
      "step= 494 ; loss =  0.0015815244065161614\n",
      "step= 495 ; loss =  0.001578121541998494\n",
      "step= 496 ; loss =  0.0015747329714528137\n",
      "step= 497 ; loss =  0.001571358605842732\n",
      "step= 498 ; loss =  0.0015679983568658807\n",
      "step= 499 ; loss =  0.001564652136946372\n",
      "step= 500 ; loss =  0.001561319859227357\n",
      "step= 501 ; loss =  0.0015580014375637381\n",
      "step= 502 ; loss =  0.0015546967865148525\n",
      "step= 503 ; loss =  0.0015514058213373363\n",
      "step= 504 ; loss =  0.0015481284579780777\n",
      "step= 505 ; loss =  0.0015448646130671996\n",
      "step= 506 ; loss =  0.0015416142039111787\n",
      "step= 507 ; loss =  0.0015383771484859623\n",
      "step= 508 ; loss =  0.0015351533654303173\n",
      "step= 509 ; loss =  0.001531942774039117\n",
      "step= 510 ; loss =  0.0015287452942567702\n",
      "step= 511 ; loss =  0.00152556084667073\n",
      "step= 512 ; loss =  0.0015223893525050968\n",
      "step= 513 ; loss =  0.0015192307336142114\n",
      "step= 514 ; loss =  0.001516084912476451\n",
      "step= 515 ; loss =  0.0015129518121879968\n",
      "step= 516 ; loss =  0.0015098313564567208\n",
      "step= 517 ; loss =  0.001506723469596134\n",
      "step= 518 ; loss =  0.0015036280765194365\n",
      "step= 519 ; loss =  0.0015005451027335676\n",
      "step= 520 ; loss =  0.0014974744743333859\n",
      "step= 521 ; loss =  0.0014944161179959248\n",
      "step= 522 ; loss =  0.00149136996097465\n",
      "step= 523 ; loss =  0.0014883359310938595\n",
      "step= 524 ; loss =  0.0014853139567431006\n",
      "step= 525 ; loss =  0.0014823039668716623\n",
      "step= 526 ; loss =  0.0014793058909831406\n",
      "step= 527 ; loss =  0.0014763196591300546\n",
      "step= 528 ; loss =  0.0014733452019085682\n",
      "step= 529 ; loss =  0.0014703824504531781\n",
      "step= 530 ; loss =  0.001467431336431558\n",
      "step= 531 ; loss =  0.0014644917920394308\n",
      "step= 532 ; loss =  0.0014615637499954695\n",
      "step= 533 ; loss =  0.001458647143536333\n",
      "step= 534 ; loss =  0.0014557419064116302\n",
      "step= 535 ; loss =  0.0014528479728790856\n",
      "step= 536 ; loss =  0.001449965277699664\n",
      "step= 537 ; loss =  0.0014470937561327879\n",
      "step= 538 ; loss =  0.001444233343931625\n",
      "step= 539 ; loss =  0.001441383977338335\n",
      "step= 540 ; loss =  0.001438545593079556\n",
      "step= 541 ; loss =  0.0014357181283616998\n",
      "step= 542 ; loss =  0.0014329015208665238\n",
      "step= 543 ; loss =  0.0014300957087466277\n",
      "step= 544 ; loss =  0.0014273006306210144\n",
      "step= 545 ; loss =  0.00142451622557072\n",
      "step= 546 ; loss =  0.0014217424331345197\n",
      "step= 547 ; loss =  0.0014189791933046174\n",
      "step= 548 ; loss =  0.0014162264465224267\n",
      "step= 549 ; loss =  0.0014134841336744066\n",
      "step= 550 ; loss =  0.0014107521960879004\n",
      "step= 551 ; loss =  0.001408030575527057\n",
      "step= 552 ; loss =  0.001405319214188814\n",
      "step= 553 ; loss =  0.0014026180546988412\n",
      "step= 554 ; loss =  0.00139992704010763\n",
      "step= 555 ; loss =  0.0013972461138865855\n",
      "step= 556 ; loss =  0.001394575219924123\n",
      "step= 557 ; loss =  0.0013919143025218875\n",
      "step= 558 ; loss =  0.001389263306390927\n",
      "step= 559 ; loss =  0.0013866221766479577\n",
      "step= 560 ; loss =  0.0013839908588117226\n",
      "step= 561 ; loss =  0.0013813692987992379\n",
      "step= 562 ; loss =  0.0013787574429222067\n",
      "step= 563 ; loss =  0.0013761552378835004\n",
      "step= 564 ; loss =  0.0013735626307735177\n",
      "step= 565 ; loss =  0.001370979569066717\n",
      "step= 566 ; loss =  0.0013684060006182068\n",
      "step= 567 ; loss =  0.0013658418736602089\n",
      "step= 568 ; loss =  0.0013632871367987441\n",
      "step= 569 ; loss =  0.0013607417390102937\n",
      "step= 570 ; loss =  0.001358205629638362\n",
      "step= 571 ; loss =  0.0013556787583903175\n",
      "step= 572 ; loss =  0.001353161075334121\n",
      "step= 573 ; loss =  0.0013506525308950338\n",
      "step= 574 ; loss =  0.001348153075852526\n",
      "step= 575 ; loss =  0.0013456626613370577\n",
      "step= 576 ; loss =  0.0013431812388270583\n",
      "step= 577 ; loss =  0.0013407087601457436\n",
      "step= 578 ; loss =  0.001338245177458116\n",
      "step= 579 ; loss =  0.0013357904432679656\n",
      "step= 580 ; loss =  0.0013333445104148686\n",
      "step= 581 ; loss =  0.0013309073320712241\n",
      "step= 582 ; loss =  0.0013284788617393519\n",
      "step= 583 ; loss =  0.0013260590532485836\n",
      "step= 584 ; loss =  0.0013236478607524188\n",
      "step= 585 ; loss =  0.0013212452387256764\n",
      "step= 586 ; loss =  0.001318851141961755\n",
      "step= 587 ; loss =  0.0013164655255697502\n",
      "step= 588 ; loss =  0.001314088344971787\n",
      "step= 589 ; loss =  0.001311719555900316\n",
      "step= 590 ; loss =  0.001309359114395401\n",
      "step= 591 ; loss =  0.0013070069768020315\n",
      "step= 592 ; loss =  0.0013046630997675464\n",
      "step= 593 ; loss =  0.0013023274402390083\n",
      "step= 594 ; loss =  0.0012999999554606117\n",
      "step= 595 ; loss =  0.001297680602971159\n",
      "step= 596 ; loss =  0.001295369340601515\n",
      "step= 597 ; loss =  0.0012930661264721013\n",
      "step= 598 ; loss =  0.0012907709189904622\n",
      "step= 599 ; loss =  0.0012884836768487912\n",
      "step= 600 ; loss =  0.0012862043590214783\n",
      "step= 601 ; loss =  0.0012839329247627798\n",
      "step= 602 ; loss =  0.0012816693336043879\n",
      "step= 603 ; loss =  0.001279413545353105\n",
      "step= 604 ; loss =  0.001277165520088508\n",
      "step= 605 ; loss =  0.001274925218160651\n",
      "step= 606 ; loss =  0.0012726926001877955\n",
      "step= 607 ; loss =  0.0012704676270541373\n",
      "step= 608 ; loss =  0.0012682502599075816\n",
      "step= 609 ; loss =  0.0012660404601575214\n",
      "step= 610 ; loss =  0.0012638381894726665\n",
      "step= 611 ; loss =  0.0012616434097788647\n",
      "step= 612 ; loss =  0.001259456083256978\n",
      "step= 613 ; loss =  0.0012572761723406909\n",
      "step= 614 ; loss =  0.0012551036397145034\n",
      "step= 615 ; loss =  0.0012529384483115737\n",
      "step= 616 ; loss =  0.0012507805613116872\n",
      "step= 617 ; loss =  0.0012486299421392492\n",
      "step= 618 ; loss =  0.0012464865544611575\n",
      "step= 619 ; loss =  0.0012443503621849313\n",
      "step= 620 ; loss =  0.0012422213294566431\n",
      "step= 621 ; loss =  0.0012400994206590008\n",
      "step= 622 ; loss =  0.001237984600409368\n",
      "step= 623 ; loss =  0.0012358768335578745\n",
      "step= 624 ; loss =  0.0012337760851854967\n",
      "step= 625 ; loss =  0.001231682320602187\n",
      "step= 626 ; loss =  0.0012295955053449705\n",
      "step= 627 ; loss =  0.0012275156051761258\n",
      "step= 628 ; loss =  0.0012254425860813451\n",
      "step= 629 ; loss =  0.0012233764142679426\n",
      "step= 630 ; loss =  0.0012213170561630106\n",
      "step= 631 ; loss =  0.0012192644784116884\n",
      "step= 632 ; loss =  0.001217218647875377\n",
      "step= 633 ; loss =  0.0012151795316299974\n",
      "step= 634 ; loss =  0.0012131470969642699\n",
      "step= 635 ; loss =  0.0012111213113779804\n",
      "step= 636 ; loss =  0.0012091021425803326\n",
      "step= 637 ; loss =  0.0012070895584882124\n",
      "step= 638 ; loss =  0.0012050835272245952\n",
      "step= 639 ; loss =  0.0012030840171168176\n",
      "step= 640 ; loss =  0.0012010909966950153\n",
      "step= 641 ; loss =  0.0011991044346904688\n",
      "step= 642 ; loss =  0.001197124300034032\n",
      "step= 643 ; loss =  0.0011951505618545185\n",
      "step= 644 ; loss =  0.0011931831894771549\n",
      "step= 645 ; loss =  0.0011912221524220132\n",
      "step= 646 ; loss =  0.0011892674204024853\n",
      "step= 647 ; loss =  0.001187318963323754\n",
      "step= 648 ; loss =  0.0011853767512812559\n",
      "step= 649 ; loss =  0.001183440754559218\n",
      "step= 650 ; loss =  0.001181510943629168\n",
      "step= 651 ; loss =  0.001179587289148463\n",
      "step= 652 ; loss =  0.0011776697619588156\n",
      "step= 653 ; loss =  0.0011757583330849104\n",
      "step= 654 ; loss =  0.0011738529737328775\n",
      "step= 655 ; loss =  0.0011719536552889944\n",
      "step= 656 ; loss =  0.001170060349318193\n",
      "step= 657 ; loss =  0.0011681730275626993\n",
      "step= 658 ; loss =  0.0011662916619406996\n",
      "step= 659 ; loss =  0.0011644162245449232\n",
      "step= 660 ; loss =  0.001162546687641298\n",
      "step= 661 ; loss =  0.0011606830236676666\n",
      "step= 662 ; loss =  0.0011588252052323741\n",
      "step= 663 ; loss =  0.001156973205113035\n",
      "step= 664 ; loss =  0.0011551269962551934\n",
      "step= 665 ; loss =  0.0011532865517710422\n",
      "step= 666 ; loss =  0.0011514518449381335\n",
      "step= 667 ; loss =  0.001149622849198149\n",
      "step= 668 ; loss =  0.0011477995381556018\n",
      "step= 669 ; loss =  0.0011459818855766189\n",
      "step= 670 ; loss =  0.0011441698653877072\n",
      "step= 671 ; loss =  0.0011423634516745302\n",
      "step= 672 ; loss =  0.001140562618680714\n",
      "step= 673 ; loss =  0.0011387673408066222\n",
      "step= 674 ; loss =  0.00113697759260818\n",
      "step= 675 ; loss =  0.001135193348795731\n",
      "step= 676 ; loss =  0.0011334145842328124\n",
      "step= 677 ; loss =  0.0011316412739350362\n",
      "step= 678 ; loss =  0.0011298733930689643\n",
      "step= 679 ; loss =  0.0011281109169509057\n",
      "step= 680 ; loss =  0.0011263538210458694\n",
      "step= 681 ; loss =  0.0011246020809664052\n",
      "step= 682 ; loss =  0.0011228556724715143\n",
      "step= 683 ; loss =  0.0011211145714655594\n",
      "step= 684 ; loss =  0.0011193787539971402\n",
      "step= 685 ; loss =  0.0011176481962581087\n",
      "step= 686 ; loss =  0.001115922874582379\n",
      "step= 687 ; loss =  0.0011142027654449903\n",
      "step= 688 ; loss =  0.0011124878454610023\n",
      "step= 689 ; loss =  0.001110778091384447\n",
      "step= 690 ; loss =  0.00110907348010734\n",
      "step= 691 ; loss =  0.0011073739886586155\n",
      "step= 692 ; loss =  0.0011056795942031765\n",
      "step= 693 ; loss =  0.0011039902740408293\n",
      "step= 694 ; loss =  0.001102306005605348\n",
      "step= 695 ; loss =  0.001100626766463457\n",
      "step= 696 ; loss =  0.0010989525343138504\n",
      "step= 697 ; loss =  0.00109728328698625\n",
      "step= 698 ; loss =  0.001095619002440447\n",
      "step= 699 ; loss =  0.0010939596587653355\n",
      "step= 700 ; loss =  0.0010923052341779847\n",
      "step= 701 ; loss =  0.0010906557070226887\n",
      "step= 702 ; loss =  0.0010890110557700721\n",
      "step= 703 ; loss =  0.001087371259016126\n",
      "step= 704 ; loss =  0.0010857362954813771\n",
      "step= 705 ; loss =  0.0010841061440098844\n",
      "step= 706 ; loss =  0.0010824807835684474\n",
      "step= 707 ; loss =  0.0010808601932456305\n",
      "step= 708 ; loss =  0.0010792443522509628\n",
      "step= 709 ; loss =  0.001077633239914013\n",
      "step= 710 ; loss =  0.001076026835683567\n",
      "step= 711 ; loss =  0.0010744251191267176\n",
      "step= 712 ; loss =  0.0010728280699281183\n",
      "step= 713 ; loss =  0.0010712356678889865\n",
      "step= 714 ; loss =  0.0010696478929264309\n",
      "step= 715 ; loss =  0.0010680647250725175\n",
      "step= 716 ; loss =  0.0010664861444735138\n",
      "step= 717 ; loss =  0.001064912131389019\n",
      "step= 718 ; loss =  0.0010633426661912275\n",
      "step= 719 ; loss =  0.0010617777293640501\n",
      "step= 720 ; loss =  0.0010602173015023916\n",
      "step= 721 ; loss =  0.00105866136331133\n",
      "step= 722 ; loss =  0.001057109895605343\n",
      "step= 723 ; loss =  0.0010555628793075496\n",
      "step= 724 ; loss =  0.0010540202954489393\n",
      "step= 725 ; loss =  0.0010524821251675746\n",
      "step= 726 ; loss =  0.0010509483497079134\n",
      "step= 727 ; loss =  0.0010494189504199978\n",
      "step= 728 ; loss =  0.0010478939087587523\n",
      "step= 729 ; loss =  0.001046373206283228\n",
      "step= 730 ; loss =  0.0010448568246558853\n",
      "step= 731 ; loss =  0.0010433447456418554\n",
      "step= 732 ; loss =  0.0010418369511082817\n",
      "step= 733 ; loss =  0.0010403334230235063\n",
      "step= 734 ; loss =  0.0010388341434564854\n",
      "step= 735 ; loss =  0.001037339094576021\n",
      "step= 736 ; loss =  0.0010358482586500378\n",
      "step= 737 ; loss =  0.0010343616180450003\n",
      "step= 738 ; loss =  0.0010328791552251379\n",
      "step= 739 ; loss =  0.0010314008527518208\n",
      "step= 740 ; loss =  0.0010299266932828734\n",
      "step= 741 ; loss =  0.001028456659571906\n",
      "step= 742 ; loss =  0.0010269907344676692\n",
      "step= 743 ; loss =  0.001025528900913383\n",
      "step= 744 ; loss =  0.0010240711419461186\n",
      "step= 745 ; loss =  0.001022617440696109\n",
      "step= 746 ; loss =  0.0010211677803861827\n",
      "step= 747 ; loss =  0.001019722144331044\n",
      "step= 748 ; loss =  0.0010182805159367398\n",
      "step= 749 ; loss =  0.0010168428786999453\n",
      "step= 750 ; loss =  0.0010154092162074167\n",
      "step= 751 ; loss =  0.001013979512135356\n",
      "step= 752 ; loss =  0.0010125537502487902\n",
      "step= 753 ; loss =  0.0010111319144009987\n",
      "step= 754 ; loss =  0.0010097139885329\n",
      "step= 755 ; loss =  0.0010082999566724431\n",
      "step= 756 ; loss =  0.0010068898029340627\n",
      "step= 757 ; loss =  0.0010054835115180535\n",
      "step= 758 ; loss =  0.0010040810667100223\n",
      "step= 759 ; loss =  0.0010026824528802996\n",
      "step= 760 ; loss =  0.0010012876544833623\n",
      "step= 761 ; loss =  0.0009998966560573277\n",
      "step= 762 ; loss =  0.0009985094422232856\n",
      "step= 763 ; loss =  0.0009971259976848481\n",
      "step= 764 ; loss =  0.0009957463072275497\n",
      "step= 765 ; loss =  0.000994370355718314\n",
      "step= 766 ; loss =  0.000992998128104902\n",
      "step= 767 ; loss =  0.0009916296094153892\n",
      "step= 768 ; loss =  0.0009902647847575819\n",
      "step= 769 ; loss =  0.0009889036393185909\n",
      "step= 770 ; loss =  0.000987546158364208\n",
      "step= 771 ; loss =  0.000986192327238429\n",
      "step= 772 ; loss =  0.0009848421313629443\n",
      "step= 773 ; loss =  0.0009834955562365798\n",
      "step= 774 ; loss =  0.000982152587434865\n",
      "step= 775 ; loss =  0.0009808132106094694\n",
      "step= 776 ; loss =  0.0009794774114877003\n",
      "step= 777 ; loss =  0.000978145175872051\n",
      "step= 778 ; loss =  0.000976816489639655\n",
      "step= 779 ; loss =  0.0009754913387418609\n",
      "step= 780 ; loss =  0.0009741697092036674\n",
      "step= 781 ; loss =  0.0009728515871233269\n",
      "step= 782 ; loss =  0.0009715369586717909\n",
      "step= 783 ; loss =  0.0009702258100922951\n",
      "step= 784 ; loss =  0.0009689181276998672\n",
      "step= 785 ; loss =  0.000967613897880835\n",
      "step= 786 ; loss =  0.0009663131070924235\n",
      "step= 787 ; loss =  0.0009650157418622479\n",
      "step= 788 ; loss =  0.0009637217887878555\n",
      "step= 789 ; loss =  0.0009624312345363073\n",
      "step= 790 ; loss =  0.0009611440658437085\n",
      "step= 791 ; loss =  0.0009598602695147689\n",
      "step= 792 ; loss =  0.0009585798324223507\n",
      "step= 793 ; loss =  0.0009573027415070509\n",
      "step= 794 ; loss =  0.0009560289837767394\n",
      "step= 795 ; loss =  0.0009547585463061581\n",
      "step= 796 ; loss =  0.0009534914162364638\n",
      "step= 797 ; loss =  0.0009522275807748407\n",
      "step= 798 ; loss =  0.0009509670271940203\n",
      "step= 799 ; loss =  0.000949709742831916\n",
      "step= 800 ; loss =  0.0009484557150911939\n",
      "step= 801 ; loss =  0.0009472049314388526\n",
      "step= 802 ; loss =  0.0009459573794058133\n",
      "step= 803 ; loss =  0.0009447130465865158\n",
      "step= 804 ; loss =  0.0009434719206385325\n",
      "step= 805 ; loss =  0.0009422339892821359\n",
      "step= 806 ; loss =  0.0009409992402999544\n",
      "step= 807 ; loss =  0.0009397676615364979\n",
      "step= 808 ; loss =  0.0009385392408978338\n",
      "step= 809 ; loss =  0.0009373139663512089\n",
      "step= 810 ; loss =  0.0009360918259246028\n",
      "step= 811 ; loss =  0.000934872807706358\n",
      "step= 812 ; loss =  0.0009336568998448917\n",
      "step= 813 ; loss =  0.0009324440905481836\n",
      "step= 814 ; loss =  0.0009312343680834959\n",
      "step= 815 ; loss =  0.0009300277207769662\n",
      "step= 816 ; loss =  0.0009288241370132712\n",
      "step= 817 ; loss =  0.0009276236052351971\n",
      "step= 818 ; loss =  0.0009264261139433592\n",
      "step= 819 ; loss =  0.000925231651695781\n",
      "step= 820 ; loss =  0.000924040207107559\n",
      "step= 821 ; loss =  0.0009228517688505189\n",
      "step= 822 ; loss =  0.0009216663256528421\n",
      "step= 823 ; loss =  0.0009204838662987436\n",
      "step= 824 ; loss =  0.0009193043796280751\n",
      "step= 825 ; loss =  0.0009181278545360531\n",
      "step= 826 ; loss =  0.0009169542799728567\n",
      "step= 827 ; loss =  0.0009157836449433272\n",
      "step= 828 ; loss =  0.0009146159385065975\n",
      "step= 829 ; loss =  0.0009134511497757824\n",
      "step= 830 ; loss =  0.0009122892679176628\n",
      "step= 831 ; loss =  0.000911130282152303\n",
      "step= 832 ; loss =  0.0009099741817527884\n",
      "step= 833 ; loss =  0.0009088209560448302\n",
      "step= 834 ; loss =  0.0009076705944065271\n",
      "step= 835 ; loss =  0.0009065230862679776\n",
      "step= 836 ; loss =  0.0009053784211109825\n",
      "step= 837 ; loss =  0.0009042365884687413\n",
      "step= 838 ; loss =  0.000903097577925543\n",
      "step= 839 ; loss =  0.0009019613791164212\n",
      "step= 840 ; loss =  0.0009008279817269028\n",
      "step= 841 ; loss =  0.000899697375492647\n",
      "step= 842 ; loss =  0.0008985695501991617\n",
      "step= 843 ; loss =  0.0008974444956815252\n",
      "step= 844 ; loss =  0.0008963222018240482\n",
      "step= 845 ; loss =  0.0008952026585600006\n",
      "step= 846 ; loss =  0.0008940858558713257\n",
      "step= 847 ; loss =  0.0008929717837882999\n",
      "step= 848 ; loss =  0.0008918604323893158\n",
      "step= 849 ; loss =  0.0008907517918005278\n",
      "step= 850 ; loss =  0.0008896458521956048\n",
      "step= 851 ; loss =  0.0008885426037954143\n",
      "step= 852 ; loss =  0.0008874420368677677\n",
      "step= 853 ; loss =  0.0008863441417271439\n",
      "step= 854 ; loss =  0.0008852489087343692\n",
      "step= 855 ; loss =  0.0008841563282963821\n",
      "step= 856 ; loss =  0.0008830663908659532\n",
      "step= 857 ; loss =  0.0008819790869413975\n",
      "step= 858 ; loss =  0.0008808944070663119\n",
      "step= 859 ; loss =  0.0008798123418293102\n",
      "step= 860 ; loss =  0.0008787328818637451\n",
      "step= 861 ; loss =  0.0008776560178474443\n",
      "step= 862 ; loss =  0.0008765817405024769\n",
      "step= 863 ; loss =  0.0008755100405948468\n",
      "step= 864 ; loss =  0.0008744409089342723\n",
      "step= 865 ; loss =  0.0008733743363738989\n",
      "step= 866 ; loss =  0.000872310313810063\n",
      "step= 867 ; loss =  0.0008712488321820397\n",
      "step= 868 ; loss =  0.0008701898824717617\n",
      "step= 869 ; loss =  0.0008691334557036072\n",
      "step= 870 ; loss =  0.0008680795429441519\n",
      "step= 871 ; loss =  0.0008670281353018568\n",
      "step= 872 ; loss =  0.0008659792239269282\n",
      "step= 873 ; loss =  0.0008649328000109634\n",
      "step= 874 ; loss =  0.0008638888547868046\n",
      "step= 875 ; loss =  0.000862847379528251\n",
      "step= 876 ; loss =  0.0008618083655498011\n",
      "step= 877 ; loss =  0.0008607718042064768\n",
      "step= 878 ; loss =  0.0008597376868935247\n",
      "step= 879 ; loss =  0.000858706005046241\n",
      "step= 880 ; loss =  0.0008576767501396823\n",
      "step= 881 ; loss =  0.000856649913688486\n",
      "step= 882 ; loss =  0.0008556254872466008\n",
      "step= 883 ; loss =  0.0008546034624070934\n",
      "step= 884 ; loss =  0.0008535838308019211\n",
      "step= 885 ; loss =  0.0008525665841016581\n",
      "step= 886 ; loss =  0.0008515517140153435\n",
      "step= 887 ; loss =  0.0008505392122902212\n",
      "step= 888 ; loss =  0.0008495290707115095\n",
      "step= 889 ; loss =  0.0008485212811022115\n",
      "step= 890 ; loss =  0.000847515835322894\n",
      "step= 891 ; loss =  0.0008465127252714765\n",
      "step= 892 ; loss =  0.0008455119428829823\n",
      "step= 893 ; loss =  0.0008445134801293658\n",
      "step= 894 ; loss =  0.0008435173290193024\n",
      "step= 895 ; loss =  0.000842523481597943\n",
      "step= 896 ; loss =  0.0008415319299467464\n",
      "step= 897 ; loss =  0.0008405426661832436\n",
      "step= 898 ; loss =  0.0008395556824608724\n",
      "step= 899 ; loss =  0.0008385709709687107\n",
      "step= 900 ; loss =  0.0008375885239313313\n",
      "step= 901 ; loss =  0.0008366083336085999\n",
      "step= 902 ; loss =  0.0008356303922954195\n",
      "step= 903 ; loss =  0.0008346546923216023\n",
      "step= 904 ; loss =  0.0008336812260516161\n",
      "step= 905 ; loss =  0.0008327099858844526\n",
      "step= 906 ; loss =  0.0008317409642533569\n",
      "step= 907 ; loss =  0.0008307741536256779\n",
      "step= 908 ; loss =  0.0008298095465027049\n",
      "step= 909 ; loss =  0.0008288471354194076\n",
      "step= 910 ; loss =  0.0008278869129443031\n",
      "step= 911 ; loss =  0.0008269288716792576\n",
      "step= 912 ; loss =  0.0008259730042592734\n",
      "step= 913 ; loss =  0.0008250193033523466\n",
      "step= 914 ; loss =  0.0008240677616592339\n",
      "step= 915 ; loss =  0.0008231183719133173\n",
      "step= 916 ; loss =  0.0008221711268803898\n",
      "step= 917 ; loss =  0.0008212260193584982\n",
      "step= 918 ; loss =  0.000820283042177756\n",
      "step= 919 ; loss =  0.0008193421882001299\n",
      "step= 920 ; loss =  0.0008184034503193498\n",
      "step= 921 ; loss =  0.0008174668214606402\n",
      "step= 922 ; loss =  0.0008165322945805887\n",
      "step= 923 ; loss =  0.0008155998626669861\n",
      "step= 924 ; loss =  0.0008146695187386448\n",
      "step= 925 ; loss =  0.0008137412558451927\n",
      "step= 926 ; loss =  0.0008128150670669579\n",
      "step= 927 ; loss =  0.0008118909455147582\n",
      "step= 928 ; loss =  0.000810968884329752\n",
      "step= 929 ; loss =  0.0008100488766832962\n",
      "step= 930 ; loss =  0.0008091309157767225\n",
      "step= 931 ; loss =  0.0008082149948412155\n",
      "step= 932 ; loss =  0.0008073011071376549\n",
      "step= 933 ; loss =  0.0008063892459564063\n",
      "step= 934 ; loss =  0.0008054794046172425\n",
      "step= 935 ; loss =  0.0008045715764690744\n",
      "step= 936 ; loss =  0.0008036657548898948\n",
      "step= 937 ; loss =  0.0008027619332865539\n",
      "step= 938 ; loss =  0.0008018601050946603\n",
      "step= 939 ; loss =  0.0008009602637783251\n",
      "step= 940 ; loss =  0.0008000624028301408\n",
      "step= 941 ; loss =  0.0007991665157709219\n",
      "step= 942 ; loss =  0.0007982725961495941\n",
      "step= 943 ; loss =  0.0007973806375430456\n",
      "step= 944 ; loss =  0.0007964906335559824\n",
      "step= 945 ; loss =  0.0007956025778207077\n",
      "step= 946 ; loss =  0.0007947164639971057\n",
      "step= 947 ; loss =  0.0007938322857723658\n",
      "step= 948 ; loss =  0.0007929500368609012\n",
      "step= 949 ; loss =  0.0007920697110042013\n",
      "step= 950 ; loss =  0.0007911913019706644\n",
      "step= 951 ; loss =  0.000790314803555453\n",
      "step= 952 ; loss =  0.0007894402095803869\n",
      "step= 953 ; loss =  0.0007885675138937607\n",
      "step= 954 ; loss =  0.0007876967103702112\n",
      "step= 955 ; loss =  0.0007868277929105973\n",
      "step= 956 ; loss =  0.0007859607554418319\n",
      "step= 957 ; loss =  0.0007850955919167734\n",
      "step= 958 ; loss =  0.0007842322963140567\n",
      "step= 959 ; loss =  0.0007833708626379777\n",
      "step= 960 ; loss =  0.0007825112849183509\n",
      "step= 961 ; loss =  0.0007816535572103768\n",
      "step= 962 ; loss =  0.0007807976735944944\n",
      "step= 963 ; loss =  0.0007799436281762671\n",
      "step= 964 ; loss =  0.0007790914150862496\n",
      "step= 965 ; loss =  0.000778241028479822\n",
      "step= 966 ; loss =  0.000777392462537104\n",
      "step= 967 ; loss =  0.0007765457114628045\n",
      "step= 968 ; loss =  0.0007757007694860899\n",
      "step= 969 ; loss =  0.0007748576308604632\n",
      "step= 970 ; loss =  0.0007740162898636071\n",
      "step= 971 ; loss =  0.0007731767407973063\n",
      "step= 972 ; loss =  0.0007723389779872999\n",
      "step= 973 ; loss =  0.0007715029957831364\n",
      "step= 974 ; loss =  0.0007706687885580669\n",
      "step= 975 ; loss =  0.0007698363507089403\n",
      "step= 976 ; loss =  0.0007690056766560309\n",
      "step= 977 ; loss =  0.0007681767608429646\n",
      "step= 978 ; loss =  0.0007673495977365673\n",
      "step= 979 ; loss =  0.0007665241818267687\n",
      "step= 980 ; loss =  0.0007657005076264378\n",
      "step= 981 ; loss =  0.0007648785696713529\n",
      "step= 982 ; loss =  0.0007640583625199552\n",
      "step= 983 ; loss =  0.0007632398807533525\n",
      "step= 984 ; loss =  0.0007624231189751231\n",
      "step= 985 ; loss =  0.0007616080718112336\n",
      "step= 986 ; loss =  0.0007607947339099146\n",
      "step= 987 ; loss =  0.0007599830999415486\n",
      "step= 988 ; loss =  0.0007591731645985667\n",
      "step= 989 ; loss =  0.0007583649225953064\n",
      "step= 990 ; loss =  0.0007575583686679167\n",
      "step= 991 ; loss =  0.0007567534975742529\n",
      "step= 992 ; loss =  0.0007559503040937575\n",
      "step= 993 ; loss =  0.0007551487830273394\n",
      "step= 994 ; loss =  0.0007543489291972844\n",
      "step= 995 ; loss =  0.0007535507374471384\n",
      "step= 996 ; loss =  0.000752754202641569\n",
      "step= 997 ; loss =  0.0007519593196663232\n",
      "step= 998 ; loss =  0.0007511660834280611\n",
      "step= 999 ; loss =  0.0007503744888542542\n",
      "step= 1000 ; loss =  0.0007495845308931178\n",
      "step= 1001 ; loss =  0.0007487962045134916\n",
      "step= 1002 ; loss =  0.0007480095047046685\n",
      "step= 1003 ; loss =  0.0007472244264764216\n",
      "step= 1004 ; loss =  0.0007464409648587809\n",
      "step= 1005 ; loss =  0.0007456591149019803\n",
      "step= 1006 ; loss =  0.0007448788716763658\n",
      "step= 1007 ; loss =  0.0007441002302722678\n",
      "step= 1008 ; loss =  0.0007433231857999177\n",
      "step= 1009 ; loss =  0.0007425477333893468\n",
      "step= 1010 ; loss =  0.0007417738681902665\n",
      "step= 1011 ; loss =  0.000741001585371979\n",
      "step= 1012 ; loss =  0.0007402308801233094\n",
      "step= 1013 ; loss =  0.0007394617476524694\n",
      "step= 1014 ; loss =  0.0007386941831869675\n",
      "step= 1015 ; loss =  0.0007379281819735103\n",
      "step= 1016 ; loss =  0.0007371637392779421\n",
      "step= 1017 ; loss =  0.0007364008503850841\n",
      "step= 1018 ; loss =  0.0007356395105987028\n",
      "step= 1019 ; loss =  0.0007348797152413731\n",
      "step= 1020 ; loss =  0.0007341214596544094\n",
      "step= 1021 ; loss =  0.0007333647391977499\n",
      "step= 1022 ; loss =  0.0007326095492498829\n",
      "step= 1023 ; loss =  0.0007318558852077473\n",
      "step= 1024 ; loss =  0.0007311037424866576\n",
      "step= 1025 ; loss =  0.0007303531165201563\n",
      "step= 1026 ; loss =  0.0007296040027599994\n",
      "step= 1027 ; loss =  0.0007288563966760234\n",
      "step= 1028 ; loss =  0.0007281102937560477\n",
      "step= 1029 ; loss =  0.0007273656895058149\n",
      "step= 1030 ; loss =  0.0007266225794488751\n",
      "step= 1031 ; loss =  0.0007258809591265316\n",
      "step= 1032 ; loss =  0.0007251408240977236\n",
      "step= 1033 ; loss =  0.0007244021699389145\n",
      "step= 1034 ; loss =  0.0007236649922440963\n",
      "step= 1035 ; loss =  0.00072292928662461\n",
      "step= 1036 ; loss =  0.0007221950487091078\n",
      "step= 1037 ; loss =  0.0007214622741434458\n",
      "step= 1038 ; loss =  0.0007207309585906296\n",
      "step= 1039 ; loss =  0.0007200010977307003\n",
      "step= 1040 ; loss =  0.0007192726872606661\n",
      "step= 1041 ; loss =  0.0007185457228944009\n",
      "step= 1042 ; loss =  0.0007178202003625989\n",
      "step= 1043 ; loss =  0.0007170961154126528\n",
      "step= 1044 ; loss =  0.0007163734638086128\n",
      "step= 1045 ; loss =  0.0007156522413310484\n",
      "step= 1046 ; loss =  0.0007149324437770368\n",
      "step= 1047 ; loss =  0.0007142140669600236\n",
      "step= 1048 ; loss =  0.0007134971067097721\n",
      "step= 1049 ; loss =  0.0007127815588722898\n",
      "step= 1050 ; loss =  0.0007120674193097302\n",
      "step= 1051 ; loss =  0.0007113546839003371\n",
      "step= 1052 ; loss =  0.0007106433485383222\n",
      "step= 1053 ; loss =  0.0007099334091338592\n",
      "step= 1054 ; loss =  0.0007092248616129397\n",
      "step= 1055 ; loss =  0.0007085177019173383\n",
      "step= 1056 ; loss =  0.0007078119260045086\n",
      "step= 1057 ; loss =  0.0007071075298475298\n",
      "step= 1058 ; loss =  0.0007064045094350321\n",
      "step= 1059 ; loss =  0.0007057028607711009\n",
      "step= 1060 ; loss =  0.0007050025798752041\n",
      "step= 1061 ; loss =  0.0007043036627821577\n",
      "step= 1062 ; loss =  0.0007036061055420006\n",
      "step= 1063 ; loss =  0.0007029099042199469\n",
      "step= 1064 ; loss =  0.0007022150548963283\n",
      "step= 1065 ; loss =  0.0007015215536664785\n",
      "step= 1066 ; loss =  0.0007008293966407179\n",
      "step= 1067 ; loss =  0.0007001385799442143\n",
      "step= 1068 ; loss =  0.0006994490997169784\n",
      "step= 1069 ; loss =  0.0006987609521137625\n",
      "step= 1070 ; loss =  0.0006980741333039729\n",
      "step= 1071 ; loss =  0.0006973886394716469\n",
      "step= 1072 ; loss =  0.0006967044668153315\n",
      "step= 1073 ; loss =  0.0006960216115480546\n",
      "step= 1074 ; loss =  0.0006953400698972287\n",
      "step= 1075 ; loss =  0.0006946598381046118\n",
      "step= 1076 ; loss =  0.0006939809124261978\n",
      "step= 1077 ; loss =  0.0006933032891322047\n",
      "step= 1078 ; loss =  0.0006926269645069571\n",
      "step= 1079 ; loss =  0.0006919519348488434\n",
      "step= 1080 ; loss =  0.0006912781964702377\n",
      "step= 1081 ; loss =  0.0006906057456974727\n",
      "step= 1082 ; loss =  0.0006899345788706944\n",
      "step= 1083 ; loss =  0.0006892646923438768\n",
      "step= 1084 ; loss =  0.0006885960824847457\n",
      "step= 1085 ; loss =  0.0006879287456746508\n",
      "step= 1086 ; loss =  0.0006872626783085645\n",
      "step= 1087 ; loss =  0.0006865978767950018\n",
      "step= 1088 ; loss =  0.0006859343375559762\n",
      "step= 1089 ; loss =  0.0006852720570268632\n",
      "step= 1090 ; loss =  0.000684611031656433\n",
      "step= 1091 ; loss =  0.0006839512579067281\n",
      "step= 1092 ; loss =  0.0006832927322530259\n",
      "step= 1093 ; loss =  0.0006826354511837517\n",
      "step= 1094 ; loss =  0.0006819794112004663\n",
      "step= 1095 ; loss =  0.0006813246088177329\n",
      "step= 1096 ; loss =  0.0006806710405631412\n",
      "step= 1097 ; loss =  0.0006800187029771673\n",
      "step= 1098 ; loss =  0.0006793675926131673\n",
      "step= 1099 ; loss =  0.0006787177060372998\n",
      "step= 1100 ; loss =  0.000678069039828473\n",
      "step= 1101 ; loss =  0.0006774215905782588\n",
      "step= 1102 ; loss =  0.000676775354890878\n",
      "step= 1103 ; loss =  0.0006761303293831063\n",
      "step= 1104 ; loss =  0.0006754865106842368\n",
      "step= 1105 ; loss =  0.0006748438954360129\n",
      "step= 1106 ; loss =  0.0006742024802925745\n",
      "step= 1107 ; loss =  0.0006735622619203941\n",
      "step= 1108 ; loss =  0.000672923236998234\n",
      "step= 1109 ; loss =  0.0006722854022170754\n",
      "step= 1110 ; loss =  0.0006716487542800718\n",
      "step= 1111 ; loss =  0.0006710132899024929\n",
      "step= 1112 ; loss =  0.000670379005811658\n",
      "step= 1113 ; loss =  0.0006697458987469022\n",
      "step= 1114 ; loss =  0.0006691139654594919\n",
      "step= 1115 ; loss =  0.0006684832027126087\n",
      "step= 1116 ; loss =  0.0006678536072812605\n",
      "step= 1117 ; loss =  0.0006672251759522347\n",
      "step= 1118 ; loss =  0.0006665979055240644\n",
      "step= 1119 ; loss =  0.0006659717928069563\n",
      "step= 1120 ; loss =  0.000665346834622737\n",
      "step= 1121 ; loss =  0.0006647230278048055\n",
      "step= 1122 ; loss =  0.0006641003691980973\n",
      "step= 1123 ; loss =  0.0006634788556589939\n",
      "step= 1124 ; loss =  0.0006628584840553096\n",
      "step= 1125 ; loss =  0.0006622392512662216\n",
      "step= 1126 ; loss =  0.0006616211541822018\n",
      "step= 1127 ; loss =  0.000661004189705013\n",
      "step= 1128 ; loss =  0.0006603883547476072\n",
      "step= 1129 ; loss =  0.000659773646234109\n",
      "step= 1130 ; loss =  0.0006591600610997287\n",
      "step= 1131 ; loss =  0.000658547596290795\n",
      "step= 1132 ; loss =  0.0006579362487645794\n",
      "step= 1133 ; loss =  0.0006573260154893554\n",
      "step= 1134 ; loss =  0.0006567168934442931\n",
      "step= 1135 ; loss =  0.0006561088796194395\n",
      "step= 1136 ; loss =  0.0006555019710156433\n",
      "step= 1137 ; loss =  0.0006548961646445261\n",
      "step= 1138 ; loss =  0.0006542914575284305\n",
      "step= 1139 ; loss =  0.0006536878467003532\n",
      "step= 1140 ; loss =  0.0006530853292039285\n",
      "step= 1141 ; loss =  0.0006524839020933665\n",
      "step= 1142 ; loss =  0.0006518835624334046\n",
      "step= 1143 ; loss =  0.0006512843072992423\n",
      "step= 1144 ; loss =  0.0006506861337765539\n",
      "step= 1145 ; loss =  0.0006500890389613509\n",
      "step= 1146 ; loss =  0.0006494930199600372\n",
      "step= 1147 ; loss =  0.0006488980738892724\n",
      "step= 1148 ; loss =  0.0006483041978759909\n",
      "step= 1149 ; loss =  0.0006477113890573386\n",
      "step= 1150 ; loss =  0.000647119644580593\n",
      "step= 1151 ; loss =  0.0006465289616031576\n",
      "step= 1152 ; loss =  0.0006459393372925227\n",
      "step= 1153 ; loss =  0.0006453507688261861\n",
      "step= 1154 ; loss =  0.0006447632533916466\n",
      "step= 1155 ; loss =  0.0006441767881863106\n",
      "step= 1156 ; loss =  0.0006435913704175194\n",
      "step= 1157 ; loss =  0.0006430069973024327\n",
      "step= 1158 ; loss =  0.0006424236660680188\n",
      "step= 1159 ; loss =  0.0006418413739510292\n",
      "step= 1160 ; loss =  0.000641260118197924\n",
      "step= 1161 ; loss =  0.000640679896064857\n",
      "step= 1162 ; loss =  0.000640100704817588\n",
      "step= 1163 ; loss =  0.0006395225417315098\n",
      "step= 1164 ; loss =  0.0006389454040915393\n",
      "step= 1165 ; loss =  0.0006383692891921085\n",
      "step= 1166 ; loss =  0.0006377941943371306\n",
      "step= 1167 ; loss =  0.0006372201168399383\n",
      "step= 1168 ; loss =  0.000636647054023257\n",
      "step= 1169 ; loss =  0.0006360750032191494\n",
      "step= 1170 ; loss =  0.0006355039617689934\n",
      "step= 1171 ; loss =  0.0006349339270234217\n",
      "step= 1172 ; loss =  0.0006343648963423017\n",
      "step= 1173 ; loss =  0.0006337968670946825\n",
      "step= 1174 ; loss =  0.0006332298366587483\n",
      "step= 1175 ; loss =  0.0006326638024218122\n",
      "step= 1176 ; loss =  0.0006320987617802265\n",
      "step= 1177 ; loss =  0.0006315347121393924\n",
      "step= 1178 ; loss =  0.0006309716509136838\n",
      "step= 1179 ; loss =  0.0006304095755264289\n",
      "step= 1180 ; loss =  0.0006298484834098716\n",
      "step= 1181 ; loss =  0.0006292883720051101\n",
      "step= 1182 ; loss =  0.0006287292387621201\n",
      "step= 1183 ; loss =  0.0006281710811396128\n",
      "step= 1184 ; loss =  0.0006276138966051075\n",
      "step= 1185 ; loss =  0.0006270576826348109\n",
      "step= 1186 ; loss =  0.0006265024367136405\n",
      "step= 1187 ; loss =  0.0006259481563351409\n",
      "step= 1188 ; loss =  0.0006253948390014688\n",
      "step= 1189 ; loss =  0.0006248424822233485\n",
      "step= 1190 ; loss =  0.0006242910835200623\n",
      "step= 1191 ; loss =  0.0006237406404193686\n",
      "step= 1192 ; loss =  0.000623191150457502\n",
      "step= 1193 ; loss =  0.0006226426111791153\n",
      "step= 1194 ; loss =  0.0006220950201372508\n",
      "step= 1195 ; loss =  0.0006215483748933052\n",
      "step= 1196 ; loss =  0.0006210026730170238\n",
      "step= 1197 ; loss =  0.0006204579120863803\n",
      "step= 1198 ; loss =  0.0006199140896876499\n",
      "step= 1199 ; loss =  0.0006193712034153065\n",
      "step= 1200 ; loss =  0.0006188292508719829\n",
      "step= 1201 ; loss =  0.0006182882296684812\n",
      "step= 1202 ; loss =  0.0006177481374236998\n",
      "step= 1203 ; loss =  0.000617208971764617\n",
      "step= 1204 ; loss =  0.0006166707303262611\n",
      "step= 1205 ; loss =  0.0006161334107516531\n",
      "step= 1206 ; loss =  0.0006155970106917948\n",
      "step= 1207 ; loss =  0.0006150615278056388\n",
      "step= 1208 ; loss =  0.000614526959760027\n",
      "step= 1209 ; loss =  0.0006139933042296885\n",
      "step= 1210 ; loss =  0.0006134605588971892\n",
      "step= 1211 ; loss =  0.0006129287214528926\n",
      "step= 1212 ; loss =  0.0006123977895949606\n",
      "step= 1213 ; loss =  0.0006118677610292716\n",
      "step= 1214 ; loss =  0.000611338633469428\n",
      "step= 1215 ; loss =  0.0006108104046366985\n",
      "step= 1216 ; loss =  0.0006102830722600276\n",
      "step= 1217 ; loss =  0.0006097566340759381\n",
      "step= 1218 ; loss =  0.0006092310878285428\n",
      "step= 1219 ; loss =  0.0006087064312695239\n",
      "step= 1220 ; loss =  0.0006081826621580593\n",
      "step= 1221 ; loss =  0.0006076597782608343\n",
      "step= 1222 ; loss =  0.000607137777351968\n",
      "step= 1223 ; loss =  0.0006066166572130302\n",
      "step= 1224 ; loss =  0.0006060964156329582\n",
      "step= 1225 ; loss =  0.0006055770504080765\n",
      "step= 1226 ; loss =  0.0006050585593420257\n",
      "step= 1227 ; loss =  0.0006045409402457591\n",
      "step= 1228 ; loss =  0.0006040241909374987\n",
      "step= 1229 ; loss =  0.0006035083092427138\n",
      "step= 1230 ; loss =  0.0006029932929940827\n",
      "step= 1231 ; loss =  0.0006024791400314542\n",
      "step= 1232 ; loss =  0.0006019658482018563\n",
      "step= 1233 ; loss =  0.0006014534153594126\n",
      "step= 1234 ; loss =  0.0006009418393653646\n",
      "step= 1235 ; loss =  0.0006004311180880133\n",
      "step= 1236 ; loss =  0.0005999212494026784\n",
      "step= 1237 ; loss =  0.0005994122311917062\n",
      "step= 1238 ; loss =  0.0005989040613444027\n",
      "step= 1239 ; loss =  0.0005983967377570518\n",
      "step= 1240 ; loss =  0.0005978902583328291\n",
      "step= 1241 ; loss =  0.0005973846209818296\n",
      "step= 1242 ; loss =  0.0005968798236209746\n",
      "step= 1243 ; loss =  0.0005963758641740623\n",
      "step= 1244 ; loss =  0.0005958727405716755\n",
      "step= 1245 ; loss =  0.0005953704507511913\n",
      "step= 1246 ; loss =  0.000594868992656725\n",
      "step= 1247 ; loss =  0.0005943683642391377\n",
      "step= 1248 ; loss =  0.0005938685634559568\n",
      "step= 1249 ; loss =  0.0005933695882714173\n",
      "step= 1250 ; loss =  0.0005928714366563721\n",
      "step= 1251 ; loss =  0.0005923741065882978\n",
      "step= 1252 ; loss =  0.0005918775960512695\n",
      "step= 1253 ; loss =  0.0005913819030359131\n",
      "step= 1254 ; loss =  0.0005908870255393891\n",
      "step= 1255 ; loss =  0.0005903929615653872\n",
      "step= 1256 ; loss =  0.0005898997091240527\n",
      "step= 1257 ; loss =  0.0005894072662320147\n",
      "step= 1258 ; loss =  0.0005889156309123128\n",
      "step= 1259 ; loss =  0.000588424801194405\n",
      "step= 1260 ; loss =  0.0005879347751141222\n",
      "step= 1261 ; loss =  0.0005874455507136589\n",
      "step= 1262 ; loss =  0.0005869571260415186\n",
      "step= 1263 ; loss =  0.00058646949915253\n",
      "step= 1264 ; loss =  0.0005859826681077723\n",
      "step= 1265 ; loss =  0.0005854966309746111\n",
      "step= 1266 ; loss =  0.0005850113858266084\n",
      "step= 1267 ; loss =  0.0005845269307435423\n",
      "step= 1268 ; loss =  0.0005840432638113647\n",
      "step= 1269 ; loss =  0.0005835603831221817\n",
      "step= 1270 ; loss =  0.0005830782867742148\n",
      "step= 1271 ; loss =  0.0005825969728718187\n",
      "step= 1272 ; loss =  0.0005821164395253848\n",
      "step= 1273 ; loss =  0.0005816366848513999\n",
      "step= 1274 ; loss =  0.0005811577069723574\n",
      "step= 1275 ; loss =  0.0005806795040167636\n",
      "step= 1276 ; loss =  0.0005802020741191011\n",
      "step= 1277 ; loss =  0.0005797254154198103\n",
      "step= 1278 ; loss =  0.0005792495260652897\n",
      "step= 1279 ; loss =  0.0005787744042078171\n",
      "step= 1280 ; loss =  0.0005783000480055772\n",
      "step= 1281 ; loss =  0.000577826455622607\n",
      "step= 1282 ; loss =  0.0005773536252287987\n",
      "step= 1283 ; loss =  0.0005768815549998458\n",
      "step= 1284 ; loss =  0.0005764102431172574\n",
      "step= 1285 ; loss =  0.0005759396877683037\n",
      "step= 1286 ; loss =  0.0005754698871459958\n",
      "step= 1287 ; loss =  0.0005750008394490719\n",
      "step= 1288 ; loss =  0.0005745325428819932\n",
      "step= 1289 ; loss =  0.0005740649956548873\n",
      "step= 1290 ; loss =  0.0005735981959835384\n",
      "step= 1291 ; loss =  0.0005731321420893744\n",
      "step= 1292 ; loss =  0.0005726668321994378\n",
      "step= 1293 ; loss =  0.000572202264546363\n",
      "step= 1294 ; loss =  0.0005717384373683439\n",
      "step= 1295 ; loss =  0.0005712753489091442\n",
      "step= 1296 ; loss =  0.0005708129974180318\n",
      "step= 1297 ; loss =  0.0005703513811497893\n",
      "step= 1298 ; loss =  0.0005698904983646973\n",
      "step= 1299 ; loss =  0.0005694303473284733\n",
      "step= 1300 ; loss =  0.0005689709263122857\n",
      "step= 1301 ; loss =  0.0005685122335927252\n",
      "step= 1302 ; loss =  0.0005680542674517887\n",
      "step= 1303 ; loss =  0.0005675970261768312\n",
      "step= 1304 ; loss =  0.0005671405080605665\n",
      "step= 1305 ; loss =  0.0005666847114010648\n",
      "step= 1306 ; loss =  0.0005662296345016962\n",
      "step= 1307 ; loss =  0.0005657752756711183\n",
      "step= 1308 ; loss =  0.000565321633223271\n",
      "step= 1309 ; loss =  0.0005648687054773476\n",
      "step= 1310 ; loss =  0.000564416490757773\n",
      "step= 1311 ; loss =  0.0005639649873941824\n",
      "step= 1312 ; loss =  0.0005635141937213956\n",
      "step= 1313 ; loss =  0.0005630641080794263\n",
      "step= 1314 ; loss =  0.0005626147288134148\n",
      "step= 1315 ; loss =  0.0005621660542736491\n",
      "step= 1316 ; loss =  0.0005617180828155309\n",
      "step= 1317 ; loss =  0.0005612708127995403\n",
      "step= 1318 ; loss =  0.0005608242425912359\n",
      "step= 1319 ; loss =  0.0005603783705612359\n",
      "step= 1320 ; loss =  0.0005599331950851908\n",
      "step= 1321 ; loss =  0.0005594887145437672\n",
      "step= 1322 ; loss =  0.0005590449273226141\n",
      "step= 1323 ; loss =  0.0005586018318123731\n",
      "step= 1324 ; loss =  0.0005581594264086247\n",
      "step= 1325 ; loss =  0.0005577177095118996\n",
      "step= 1326 ; loss =  0.0005572766795276533\n",
      "step= 1327 ; loss =  0.0005568363348662236\n",
      "step= 1328 ; loss =  0.0005563966739428425\n",
      "step= 1329 ; loss =  0.000555957695177602\n",
      "step= 1330 ; loss =  0.0005555193969954357\n",
      "step= 1331 ; loss =  0.0005550817778261096\n",
      "step= 1332 ; loss =  0.0005546448361041697\n",
      "step= 1333 ; loss =  0.0005542085702690051\n",
      "step= 1334 ; loss =  0.0005537729787647192\n",
      "step= 1335 ; loss =  0.0005533380600402062\n",
      "step= 1336 ; loss =  0.0005529038125490636\n",
      "step= 1337 ; loss =  0.0005524702347496305\n",
      "step= 1338 ; loss =  0.0005520373251049356\n",
      "step= 1339 ; loss =  0.0005516050820826836\n",
      "step= 1340 ; loss =  0.0005511735041552513\n",
      "step= 1341 ; loss =  0.0005507425897996565\n",
      "step= 1342 ; loss =  0.0005503123374975289\n",
      "step= 1343 ; loss =  0.0005498827457351446\n",
      "step= 1344 ; loss =  0.0005494538130033247\n",
      "step= 1345 ; loss =  0.000549025537797512\n",
      "step= 1346 ; loss =  0.0005485979186176758\n",
      "step= 1347 ; loss =  0.0005481709539683469\n",
      "step= 1348 ; loss =  0.0005477446423585538\n",
      "step= 1349 ; loss =  0.0005473189823018542\n",
      "step= 1350 ; loss =  0.0005468939723162827\n",
      "step= 1351 ; loss =  0.0005464696109243669\n",
      "step= 1352 ; loss =  0.0005460458966530656\n",
      "step= 1353 ; loss =  0.0005456228280337845\n",
      "step= 1354 ; loss =  0.0005452004036023578\n",
      "step= 1355 ; loss =  0.0005447786218990139\n",
      "step= 1356 ; loss =  0.0005443574814683926\n",
      "step= 1357 ; loss =  0.000543936980859474\n",
      "step= 1358 ; loss =  0.0005435171186256338\n",
      "step= 1359 ; loss =  0.0005430978933245428\n",
      "step= 1360 ; loss =  0.0005426793035182379\n",
      "step= 1361 ; loss =  0.0005422613477730449\n",
      "step= 1362 ; loss =  0.0005418440246595719\n",
      "step= 1363 ; loss =  0.000541427332752725\n",
      "step= 1364 ; loss =  0.000541011270631653\n",
      "step= 1365 ; loss =  0.0005405958368797437\n",
      "step= 1366 ; loss =  0.0005401810300846493\n",
      "step= 1367 ; loss =  0.0005397668488381864\n",
      "step= 1368 ; loss =  0.0005393532917363998\n",
      "step= 1369 ; loss =  0.0005389403573795033\n",
      "step= 1370 ; loss =  0.0005385280443718893\n",
      "step= 1371 ; loss =  0.0005381163513220716\n",
      "step= 1372 ; loss =  0.0005377052768427416\n",
      "step= 1373 ; loss =  0.00053729481955067\n",
      "step= 1374 ; loss =  0.0005368849780667496\n",
      "step= 1375 ; loss =  0.000536475751015973\n",
      "step= 1376 ; loss =  0.0005360671370273847\n",
      "step= 1377 ; loss =  0.000535659134734102\n",
      "step= 1378 ; loss =  0.0005352517427732889\n",
      "step= 1379 ; loss =  0.0005348449597861241\n",
      "step= 1380 ; loss =  0.0005344387844178203\n",
      "step= 1381 ; loss =  0.0005340332153175667\n",
      "step= 1382 ; loss =  0.0005336282511385559\n",
      "step= 1383 ; loss =  0.0005332238905379506\n",
      "step= 1384 ; loss =  0.0005328201321768488\n",
      "step= 1385 ; loss =  0.0005324169747203195\n",
      "step= 1386 ; loss =  0.0005320144168373234\n",
      "step= 1387 ; loss =  0.0005316124572007715\n",
      "step= 1388 ; loss =  0.0005312110944874464\n",
      "step= 1389 ; loss =  0.0005308103273780222\n",
      "step= 1390 ; loss =  0.0005304101545570398\n",
      "step= 1391 ; loss =  0.0005300105747129028\n",
      "step= 1392 ; loss =  0.0005296115865378545\n",
      "step= 1393 ; loss =  0.0005292131887279525\n",
      "step= 1394 ; loss =  0.0005288153799830811\n",
      "step= 1395 ; loss =  0.0005284181590069124\n",
      "step= 1396 ; loss =  0.0005280215245069304\n",
      "step= 1397 ; loss =  0.0005276254751943643\n",
      "step= 1398 ; loss =  0.0005272300097842016\n",
      "step= 1399 ; loss =  0.0005268351269951926\n",
      "step= 1400 ; loss =  0.0005264408255498025\n",
      "step= 1401 ; loss =  0.0005260471041742148\n",
      "step= 1402 ; loss =  0.0005256539615983348\n",
      "step= 1403 ; loss =  0.0005252613965557324\n",
      "step= 1404 ; loss =  0.0005248694077836733\n",
      "step= 1405 ; loss =  0.0005244779940230784\n",
      "step= 1406 ; loss =  0.0005240871540185246\n",
      "step= 1407 ; loss =  0.0005236968865182225\n",
      "step= 1408 ; loss =  0.0005233071902740001\n",
      "step= 1409 ; loss =  0.0005229180640413058\n",
      "step= 1410 ; loss =  0.0005225295065791962\n",
      "step= 1411 ; loss =  0.0005221415166502826\n",
      "step= 1412 ; loss =  0.0005217540930207819\n",
      "step= 1413 ; loss =  0.000521367234460446\n",
      "step= 1414 ; loss =  0.0005209809397425858\n",
      "step= 1415 ; loss =  0.0005205952076440487\n",
      "step= 1416 ; loss =  0.0005202100369451855\n",
      "step= 1417 ; loss =  0.0005198254264298823\n",
      "step= 1418 ; loss =  0.000519441374885493\n",
      "step= 1419 ; loss =  0.0005190578811028686\n",
      "step= 1420 ; loss =  0.0005186749438763503\n",
      "step= 1421 ; loss =  0.0005182925620036954\n",
      "step= 1422 ; loss =  0.000517910734286148\n",
      "step= 1423 ; loss =  0.0005175294595283532\n",
      "step= 1424 ; loss =  0.000517148736538408\n",
      "step= 1425 ; loss =  0.0005167685641277968\n",
      "step= 1426 ; loss =  0.0005163889411114063\n",
      "step= 1427 ; loss =  0.0005160098663075164\n",
      "step= 1428 ; loss =  0.0005156313385377739\n",
      "step= 1429 ; loss =  0.000515253356627186\n",
      "step= 1430 ; loss =  0.0005148759194041117\n",
      "step= 1431 ; loss =  0.000514499025700246\n",
      "step= 1432 ; loss =  0.0005141226743506062\n",
      "step= 1433 ; loss =  0.0005137468641935319\n",
      "step= 1434 ; loss =  0.000513371594070653\n",
      "step= 1435 ; loss =  0.0005129968628269023\n",
      "step= 1436 ; loss =  0.0005126226693104845\n",
      "step= 1437 ; loss =  0.0005122490123728733\n",
      "step= 1438 ; loss =  0.0005118758908687908\n",
      "step= 1439 ; loss =  0.0005115033036562118\n",
      "step= 1440 ; loss =  0.0005111312495963414\n",
      "step= 1441 ; loss =  0.0005107597275536069\n",
      "step= 1442 ; loss =  0.0005103887363956386\n",
      "step= 1443 ; loss =  0.0005100182749932764\n",
      "step= 1444 ; loss =  0.0005096483422205339\n",
      "step= 1445 ; loss =  0.0005092789369546147\n",
      "step= 1446 ; loss =  0.000508910058075875\n",
      "step= 1447 ; loss =  0.0005085417044678354\n",
      "step= 1448 ; loss =  0.0005081738750171562\n",
      "step= 1449 ; loss =  0.0005078065686136162\n",
      "step= 1450 ; loss =  0.0005074397841501443\n",
      "step= 1451 ; loss =  0.0005070735205227441\n",
      "step= 1452 ; loss =  0.0005067077766305342\n",
      "step= 1453 ; loss =  0.0005063425513757319\n",
      "step= 1454 ; loss =  0.0005059778436636174\n",
      "step= 1455 ; loss =  0.0005056136524025532\n",
      "step= 1456 ; loss =  0.0005052499765039238\n",
      "step= 1457 ; loss =  0.0005048868148821948\n",
      "step= 1458 ; loss =  0.0005045241664548537\n",
      "step= 1459 ; loss =  0.0005041620301424103\n",
      "step= 1460 ; loss =  0.0005038004048683821\n",
      "step= 1461 ; loss =  0.0005034392895592998\n",
      "step= 1462 ; loss =  0.0005030786831446866\n",
      "step= 1463 ; loss =  0.0005027185845570349\n",
      "step= 1464 ; loss =  0.0005023589927318272\n",
      "step= 1465 ; loss =  0.0005019999066074951\n",
      "step= 1466 ; loss =  0.0005016413251254201\n",
      "step= 1467 ; loss =  0.0005012832472299373\n",
      "step= 1468 ; loss =  0.0005009256718683024\n",
      "step= 1469 ; loss =  0.0005005685979906885\n",
      "step= 1470 ; loss =  0.0005002120245501895\n",
      "step= 1471 ; loss =  0.0004998559505027867\n",
      "step= 1472 ; loss =  0.0004995003748073729\n",
      "step= 1473 ; loss =  0.0004991452964256955\n",
      "step= 1474 ; loss =  0.0004987907143223927\n",
      "step= 1475 ; loss =  0.000498436627464965\n",
      "step= 1476 ; loss =  0.0004980830348237349\n",
      "step= 1477 ; loss =  0.000497729935371902\n",
      "step= 1478 ; loss =  0.0004973773280854741\n",
      "step= 1479 ; loss =  0.000497025211943294\n",
      "step= 1480 ; loss =  0.0004966735859270019\n",
      "step= 1481 ; loss =  0.0004963224490210603\n",
      "step= 1482 ; loss =  0.0004959718002126916\n",
      "step= 1483 ; loss =  0.0004956216384919427\n",
      "step= 1484 ; loss =  0.0004952719628516084\n",
      "step= 1485 ; loss =  0.0004949227722872462\n",
      "step= 1486 ; loss =  0.0004945740657971784\n",
      "step= 1487 ; loss =  0.0004942258423824752\n",
      "step= 1488 ; loss =  0.0004938781010469252\n",
      "step= 1489 ; loss =  0.0004935308407970601\n",
      "step= 1490 ; loss =  0.000493184060642117\n",
      "step= 1491 ; loss =  0.0004928377595940642\n",
      "step= 1492 ; loss =  0.0004924919366675305\n",
      "step= 1493 ; loss =  0.0004921465908798677\n",
      "step= 1494 ; loss =  0.0004918017212510881\n",
      "step= 1495 ; loss =  0.0004914573268038885\n",
      "step= 1496 ; loss =  0.0004911134065636214\n",
      "step= 1497 ; loss =  0.0004907699595582911\n",
      "step= 1498 ; loss =  0.0004904269848185427\n",
      "step= 1499 ; loss =  0.0004900844813776757\n",
      "step= 1500 ; loss =  0.0004897424482715817\n",
      "step= 1501 ; loss =  0.0004894008845388075\n",
      "step= 1502 ; loss =  0.0004890597892204884\n",
      "step= 1503 ; loss =  0.0004887191613603568\n",
      "step= 1504 ; loss =  0.0004883790000047474\n",
      "step= 1505 ; loss =  0.0004880393042025577\n",
      "step= 1506 ; loss =  0.00048770007300527856\n",
      "step= 1507 ; loss =  0.0004873613054669602\n",
      "step= 1508 ; loss =  0.00048702300064421385\n",
      "step= 1509 ; loss =  0.0004866851575961829\n",
      "step= 1510 ; loss =  0.0004863477753845562\n",
      "step= 1511 ; loss =  0.0004860108530735635\n",
      "step= 1512 ; loss =  0.0004856743897299451\n",
      "step= 1513 ; loss =  0.0004853383844229616\n",
      "step= 1514 ; loss =  0.0004850028362243703\n",
      "step= 1515 ; loss =  0.0004846677442084291\n",
      "step= 1516 ; loss =  0.000484333107451887\n",
      "step= 1517 ; loss =  0.00048399892503397636\n",
      "step= 1518 ; loss =  0.00048366519603639424\n",
      "step= 1519 ; loss =  0.00048333191954328894\n",
      "step= 1520 ; loss =  0.00048299909464129785\n",
      "step= 1521 ; loss =  0.0004826667204194741\n",
      "step= 1522 ; loss =  0.0004823347959693164\n",
      "step= 1523 ; loss =  0.00048200332038476765\n",
      "step= 1524 ; loss =  0.00048167229276218076\n",
      "step= 1525 ; loss =  0.00048134171220032225\n",
      "step= 1526 ; loss =  0.00048101157780037785\n",
      "step= 1527 ; loss =  0.00048068188866591305\n",
      "step= 1528 ; loss =  0.0004803526439028956\n",
      "step= 1529 ; loss =  0.0004800238426196804\n",
      "step= 1530 ; loss =  0.0004796954839269839\n",
      "step= 1531 ; loss =  0.00047936756693790116\n",
      "step= 1532 ; loss =  0.0004790400907678729\n",
      "step= 1533 ; loss =  0.0004787130545347071\n",
      "step= 1534 ; loss =  0.00047838645735853475\n",
      "step= 1535 ; loss =  0.00047806029836184574\n",
      "step= 1536 ; loss =  0.00047773457666943134\n",
      "step= 1537 ; loss =  0.0004774092914084394\n",
      "step= 1538 ; loss =  0.00047708444170829214\n",
      "step= 1539 ; loss =  0.0004767600267007341\n",
      "step= 1540 ; loss =  0.000476436045519811\n",
      "step= 1541 ; loss =  0.00047611249730184694\n",
      "step= 1542 ; loss =  0.0004757893811854613\n",
      "step= 1543 ; loss =  0.00047546669631153254\n",
      "step= 1544 ; loss =  0.00047514444182322106\n",
      "step= 1545 ; loss =  0.0004748226168659396\n",
      "step= 1546 ; loss =  0.0004745012205873444\n",
      "step= 1547 ; loss =  0.00047418025213735856\n",
      "step= 1548 ; loss =  0.0004738597106681245\n",
      "step= 1549 ; loss =  0.00047353959533401915\n",
      "step= 1550 ; loss =  0.000473219905291639\n",
      "step= 1551 ; loss =  0.000472900639699808\n",
      "step= 1552 ; loss =  0.00047258179771954333\n",
      "step= 1553 ; loss =  0.00047226337851407474\n",
      "step= 1554 ; loss =  0.00047194538124882513\n",
      "step= 1555 ; loss =  0.00047162780509139624\n",
      "step= 1556 ; loss =  0.0004713106492115676\n",
      "step= 1557 ; loss =  0.00047099391278130443\n",
      "step= 1558 ; loss =  0.0004706775949747349\n",
      "step= 1559 ; loss =  0.000470361694968132\n",
      "step= 1560 ; loss =  0.0004700462119399246\n",
      "step= 1561 ; loss =  0.0004697311450706929\n",
      "step= 1562 ; loss =  0.0004694164935431577\n",
      "step= 1563 ; loss =  0.0004691022565421567\n",
      "step= 1564 ; loss =  0.0004687884332546661\n",
      "step= 1565 ; loss =  0.00046847502286976006\n",
      "step= 1566 ; loss =  0.00046816202457863806\n",
      "step= 1567 ; loss =  0.00046784943757460074\n",
      "step= 1568 ; loss =  0.00046753726105302725\n",
      "step= 1569 ; loss =  0.0004672254942114189\n",
      "step= 1570 ; loss =  0.00046691413624932326\n",
      "step= 1571 ; loss =  0.00046660318636839295\n",
      "step= 1572 ; loss =  0.0004662926437723357\n",
      "step= 1573 ; loss =  0.00046598250766691153\n",
      "step= 1574 ; loss =  0.0004656727772599606\n",
      "step= 1575 ; loss =  0.00046536345176135223\n",
      "step= 1576 ; loss =  0.0004650545303830099\n",
      "step= 1577 ; loss =  0.00046474601233889275\n",
      "step= 1578 ; loss =  0.0004644378968449756\n",
      "step= 1579 ; loss =  0.0004641301831192646\n",
      "step= 1580 ; loss =  0.00046382287038178934\n",
      "step= 1581 ; loss =  0.0004635159578545864\n",
      "step= 1582 ; loss =  0.0004632094447616831\n",
      "step= 1583 ; loss =  0.00046290333032911597\n",
      "step= 1584 ; loss =  0.0004625976137849061\n",
      "step= 1585 ; loss =  0.0004622922943590698\n",
      "step= 1586 ; loss =  0.0004619873712835836\n",
      "step= 1587 ; loss =  0.00046168284379241044\n",
      "step= 1588 ; loss =  0.00046137871112147515\n",
      "step= 1589 ; loss =  0.000461074972508652\n",
      "step= 1590 ; loss =  0.000460771627193777\n",
      "step= 1591 ; loss =  0.00046046867441863363\n",
      "step= 1592 ; loss =  0.0004601661134269375\n",
      "step= 1593 ; loss =  0.0004598639434643479\n",
      "step= 1594 ; loss =  0.00045956216377844296\n",
      "step= 1595 ; loss =  0.00045926077361873214\n",
      "step= 1596 ; loss =  0.0004589597722366297\n",
      "step= 1597 ; loss =  0.0004586591588854664\n",
      "step= 1598 ; loss =  0.00045835893282047247\n",
      "step= 1599 ; loss =  0.0004580590932987868\n",
      "step= 1600 ; loss =  0.0004577596395794187\n",
      "step= 1601 ; loss =  0.00045746057092328356\n",
      "step= 1602 ; loss =  0.0004571618865931637\n",
      "step= 1603 ; loss =  0.0004568635858537103\n",
      "step= 1604 ; loss =  0.0004565656679714664\n",
      "step= 1605 ; loss =  0.00045626813221481366\n",
      "step= 1606 ; loss =  0.00045597097785399026\n",
      "step= 1607 ; loss =  0.0004556742041610931\n",
      "step= 1608 ; loss =  0.00045537781041006704\n",
      "step= 1609 ; loss =  0.00045508179587668213\n",
      "step= 1610 ; loss =  0.0004547861598385419\n",
      "step= 1611 ; loss =  0.00045449090157508504\n",
      "step= 1612 ; loss =  0.000454196020367572\n",
      "step= 1613 ; loss =  0.000453901515499066\n",
      "step= 1614 ; loss =  0.0004536073862544661\n",
      "step= 1615 ; loss =  0.0004533136319204343\n",
      "step= 1616 ; loss =  0.0004530202517854512\n",
      "step= 1617 ; loss =  0.0004527272451398105\n",
      "step= 1618 ; loss =  0.0004524346112755582\n",
      "step= 1619 ; loss =  0.0004521423494865416\n",
      "step= 1620 ; loss =  0.0004518504590683834\n",
      "step= 1621 ; loss =  0.00045155893931845897\n",
      "step= 1622 ; loss =  0.00045126778953592507\n",
      "step= 1623 ; loss =  0.0004509770090217052\n",
      "step= 1624 ; loss =  0.0004506865970784452\n",
      "step= 1625 ; loss =  0.0004503965530105659\n",
      "step= 1626 ; loss =  0.00045010687612422935\n",
      "step= 1627 ; loss =  0.0004498175657273169\n",
      "step= 1628 ; loss =  0.0004495286211294538\n",
      "step= 1629 ; loss =  0.0004492400416419934\n",
      "step= 1630 ; loss =  0.00044895182657800977\n",
      "step= 1631 ; loss =  0.0004486639752522831\n",
      "step= 1632 ; loss =  0.0004483764869813099\n",
      "step= 1633 ; loss =  0.0004480893610832927\n",
      "step= 1634 ; loss =  0.00044780259687813467\n",
      "step= 1635 ; loss =  0.00044751619368743465\n",
      "step= 1636 ; loss =  0.0004472301508344682\n",
      "step= 1637 ; loss =  0.00044694446764420603\n",
      "step= 1638 ; loss =  0.0004466591434432896\n",
      "step= 1639 ; loss =  0.0004463741775600459\n",
      "step= 1640 ; loss =  0.000446089569324468\n",
      "step= 1641 ; loss =  0.0004458053180682036\n",
      "step= 1642 ; loss =  0.0004455214231245435\n",
      "step= 1643 ; loss =  0.0004452378838284699\n",
      "step= 1644 ; loss =  0.000444954699516591\n",
      "step= 1645 ; loss =  0.00044467186952714896\n",
      "step= 1646 ; loss =  0.0004443893932000354\n",
      "step= 1647 ; loss =  0.0004441072698767774\n",
      "step= 1648 ; loss =  0.0004438254989005229\n",
      "step= 1649 ; loss =  0.00044354407961603776\n",
      "step= 1650 ; loss =  0.0004432630113697098\n",
      "step= 1651 ; loss =  0.00044298229350954433\n",
      "step= 1652 ; loss =  0.00044270192538515196\n",
      "step= 1653 ; loss =  0.00044242190634774005\n",
      "step= 1654 ; loss =  0.0004421422357501269\n",
      "step= 1655 ; loss =  0.00044186291294670197\n",
      "step= 1656 ; loss =  0.0004415839372934527\n",
      "step= 1657 ; loss =  0.00044130530814796246\n",
      "step= 1658 ; loss =  0.0004410270248693794\n",
      "step= 1659 ; loss =  0.0004407490868184186\n",
      "step= 1660 ; loss =  0.0004404714933573859\n",
      "step= 1661 ; loss =  0.00044019424385011955\n",
      "step= 1662 ; loss =  0.0004399173376620485\n",
      "step= 1663 ; loss =  0.0004396407741601298\n",
      "step= 1664 ; loss =  0.00043936455271289594\n",
      "step= 1665 ; loss =  0.00043908867269039587\n",
      "step= 1666 ; loss =  0.0004388131334642419\n",
      "step= 1667 ; loss =  0.000438537934407573\n",
      "step= 1668 ; loss =  0.00043826307489504713\n",
      "step= 1669 ; loss =  0.00043798855430286576\n",
      "step= 1670 ; loss =  0.00043771437200874837\n",
      "step= 1671 ; loss =  0.00043744052739191273\n",
      "step= 1672 ; loss =  0.0004371670198331207\n",
      "step= 1673 ; loss =  0.00043689384871461475\n",
      "step= 1674 ; loss =  0.0004366210134201494\n",
      "step= 1675 ; loss =  0.0004363485133349826\n",
      "step= 1676 ; loss =  0.00043607634784585973\n",
      "step= 1677 ; loss =  0.0004358045163410172\n",
      "step= 1678 ; loss =  0.00043553301821017\n",
      "step= 1679 ; loss =  0.00043526185284452557\n",
      "step= 1680 ; loss =  0.00043499101963676153\n",
      "step= 1681 ; loss =  0.0004347205179810236\n",
      "step= 1682 ; loss =  0.00043445034727292435\n",
      "step= 1683 ; loss =  0.000434180506909553\n",
      "step= 1684 ; loss =  0.0004339109962894323\n",
      "step= 1685 ; loss =  0.0004336418148125572\n",
      "step= 1686 ; loss =  0.00043337296188036844\n",
      "step= 1687 ; loss =  0.0004331044368957507\n",
      "step= 1688 ; loss =  0.0004328362392630248\n",
      "step= 1689 ; loss =  0.0004325683683879439\n",
      "step= 1690 ; loss =  0.0004323008236777197\n",
      "step= 1691 ; loss =  0.00043203360454095507\n",
      "step= 1692 ; loss =  0.00043176671038770416\n",
      "step= 1693 ; loss =  0.0004315001406294192\n",
      "step= 1694 ; loss =  0.0004312338946789901\n",
      "step= 1695 ; loss =  0.00043096797195068973\n",
      "step= 1696 ; loss =  0.00043070237186022955\n",
      "step= 1697 ; loss =  0.00043043709382469794\n",
      "step= 1698 ; loss =  0.0004301721372625917\n",
      "step= 1699 ; loss =  0.00042990750159378966\n",
      "step= 1700 ; loss =  0.00042964318623957997\n",
      "step= 1701 ; loss =  0.0004293791906226279\n",
      "step= 1702 ; loss =  0.00042911551416697157\n",
      "step= 1703 ; loss =  0.00042885215629803123\n",
      "step= 1704 ; loss =  0.00042858911644261244\n",
      "step= 1705 ; loss =  0.00042832639402887445\n",
      "step= 1706 ; loss =  0.0004280639884863374\n",
      "step= 1707 ; loss =  0.00042780189924590203\n",
      "step= 1708 ; loss =  0.00042754012573981945\n",
      "step= 1709 ; loss =  0.00042727866740167593\n",
      "step= 1710 ; loss =  0.00042701752366642383\n",
      "step= 1711 ; loss =  0.0004267566939703654\n",
      "step= 1712 ; loss =  0.0004264961777511253\n",
      "step= 1713 ; loss =  0.0004262359744476839\n",
      "step= 1714 ; loss =  0.00042597608350033176\n",
      "step= 1715 ; loss =  0.00042571650435070944\n",
      "step= 1716 ; loss =  0.0004254572364417839\n",
      "step= 1717 ; loss =  0.0004251982792178171\n",
      "step= 1718 ; loss =  0.0004249396321244187\n",
      "step= 1719 ; loss =  0.0004246812946084862\n",
      "step= 1720 ; loss =  0.00042442326611824327\n",
      "step= 1721 ; loss =  0.00042416554610322325\n",
      "step= 1722 ; loss =  0.00042390813401424563\n",
      "step= 1723 ; loss =  0.00042365102930342496\n",
      "step= 1724 ; loss =  0.0004233942314241944\n",
      "step= 1725 ; loss =  0.00042313773983125515\n",
      "step= 1726 ; loss =  0.00042288155398059827\n",
      "step= 1727 ; loss =  0.0004226256733295111\n",
      "step= 1728 ; loss =  0.0004223700973365368\n",
      "step= 1729 ; loss =  0.0004221148254615242\n",
      "step= 1730 ; loss =  0.0004218598571655601\n",
      "step= 1731 ; loss =  0.00042160519191102085\n",
      "step= 1732 ; loss =  0.0004213508291615462\n",
      "step= 1733 ; loss =  0.00042109676838202314\n",
      "step= 1734 ; loss =  0.00042084300903860164\n",
      "step= 1735 ; loss =  0.00042058955059868456\n",
      "step= 1736 ; loss =  0.0004203363925309398\n",
      "step= 1737 ; loss =  0.00042008353430525273\n",
      "step= 1738 ; loss =  0.0004198309753927732\n",
      "step= 1739 ; loss =  0.0004195787152658705\n",
      "step= 1740 ; loss =  0.0004193267533981615\n",
      "step= 1741 ; loss =  0.00041907508926449075\n",
      "step= 1742 ; loss =  0.0004188237223409372\n",
      "step= 1743 ; loss =  0.0004185726521047894\n",
      "step= 1744 ; loss =  0.0004183218780345702\n",
      "step= 1745 ; loss =  0.0004180713996099998\n",
      "step= 1746 ; loss =  0.0004178212163120491\n",
      "step= 1747 ; loss =  0.00041757132762285006\n",
      "step= 1748 ; loss =  0.0004173217330257775\n",
      "step= 1749 ; loss =  0.0004170724320053972\n",
      "step= 1750 ; loss =  0.0004168234240474699\n",
      "step= 1751 ; loss =  0.00041657470863895813\n",
      "step= 1752 ; loss =  0.00041632628526801175\n",
      "step= 1753 ; loss =  0.0004160781534239737\n",
      "step= 1754 ; loss =  0.00041583031259737307\n",
      "step= 1755 ; loss =  0.00041558276227992387\n",
      "step= 1756 ; loss =  0.0004153355019644952\n",
      "step= 1757 ; loss =  0.00041508853114516857\n",
      "step= 1758 ; loss =  0.0004148418493171638\n",
      "step= 1759 ; loss =  0.00041459545597690806\n",
      "step= 1760 ; loss =  0.00041434935062193963\n",
      "step= 1761 ; loss =  0.0004141035327510033\n",
      "step= 1762 ; loss =  0.0004138580018639821\n",
      "step= 1763 ; loss =  0.00041361275746191854\n",
      "step= 1764 ; loss =  0.00041336779904701864\n",
      "step= 1765 ; loss =  0.0004131231261226057\n",
      "step= 1766 ; loss =  0.0004128787381931831\n",
      "step= 1767 ; loss =  0.0004126346347643696\n",
      "step= 1768 ; loss =  0.00041239081534294155\n",
      "step= 1769 ; loss =  0.0004121472794367952\n",
      "step= 1770 ; loss =  0.00041190402655497083\n",
      "step= 1771 ; loss =  0.000411661056207627\n",
      "step= 1772 ; loss =  0.00041141836790606047\n",
      "step= 1773 ; loss =  0.0004111759611626755\n",
      "step= 1774 ; loss =  0.000410933835491005\n",
      "step= 1775 ; loss =  0.0004106919904056911\n",
      "step= 1776 ; loss =  0.00041045042542250417\n",
      "step= 1777 ; loss =  0.00041020914005829767\n",
      "step= 1778 ; loss =  0.0004099681338310622\n",
      "step= 1779 ; loss =  0.00040972740625985733\n",
      "step= 1780 ; loss =  0.00040948695686487713\n",
      "step= 1781 ; loss =  0.0004092467851673889\n",
      "step= 1782 ; loss =  0.000409006890689762\n",
      "step= 1783 ; loss =  0.0004087672729554459\n",
      "step= 1784 ; loss =  0.00040852793148900117\n",
      "step= 1785 ; loss =  0.0004082888658160553\n",
      "step= 1786 ; loss =  0.00040805007546332404\n",
      "step= 1787 ; loss =  0.00040781155995857924\n",
      "step= 1788 ; loss =  0.00040757331883070673\n",
      "step= 1789 ; loss =  0.0004073353516096353\n",
      "step= 1790 ; loss =  0.000407097657826377\n",
      "step= 1791 ; loss =  0.00040686023701299586\n",
      "step= 1792 ; loss =  0.00040662308870263714\n",
      "step= 1793 ; loss =  0.0004063862124294879\n",
      "step= 1794 ; loss =  0.0004061496077288093\n",
      "step= 1795 ; loss =  0.00040591327413690983\n",
      "step= 1796 ; loss =  0.0004056772111911389\n",
      "step= 1797 ; loss =  0.0004054414184299093\n",
      "step= 1798 ; loss =  0.00040520589539266627\n",
      "step= 1799 ; loss =  0.0004049706416199135\n",
      "step= 1800 ; loss =  0.0004047356566531801\n",
      "step= 1801 ; loss =  0.0004045009400350267\n",
      "step= 1802 ; loss =  0.0004042664913090663\n",
      "step= 1803 ; loss =  0.000404032310019928\n",
      "step= 1804 ; loss =  0.0004037983957132729\n",
      "step= 1805 ; loss =  0.000403564747935787\n",
      "step= 1806 ; loss =  0.0004033313662351775\n",
      "step= 1807 ; loss =  0.0004030982501601752\n",
      "step= 1808 ; loss =  0.00040286539926051194\n",
      "step= 1809 ; loss =  0.00040263281308695144\n",
      "step= 1810 ; loss =  0.00040240049119125675\n",
      "step= 1811 ; loss =  0.0004021684331262059\n",
      "step= 1812 ; loss =  0.0004019366384455766\n",
      "step= 1813 ; loss =  0.00040170510670414197\n",
      "step= 1814 ; loss =  0.0004014738374576888\n",
      "step= 1815 ; loss =  0.0004012428302629902\n",
      "step= 1816 ; loss =  0.0004010120846778122\n",
      "step= 1817 ; loss =  0.00040078160026092393\n",
      "step= 1818 ; loss =  0.00040055137657207053\n",
      "step= 1819 ; loss =  0.0004003214131719781\n",
      "step= 1820 ; loss =  0.00040009170962236964\n",
      "step= 1821 ; loss =  0.00039986226548594124\n",
      "step= 1822 ; loss =  0.00039963308032635216\n",
      "step= 1823 ; loss =  0.00039940415370827583\n",
      "step= 1824 ; loss =  0.000399175485197315\n",
      "step= 1825 ; loss =  0.0003989470743600539\n",
      "step= 1826 ; loss =  0.0003987189207640457\n",
      "step= 1827 ; loss =  0.00039849102397781805\n",
      "step= 1828 ; loss =  0.0003982633835708523\n",
      "step= 1829 ; loss =  0.00039803599911356606\n",
      "step= 1830 ; loss =  0.0003978088701773683\n",
      "step= 1831 ; loss =  0.0003975819963345971\n",
      "step= 1832 ; loss =  0.00039735537715853927\n",
      "step= 1833 ; loss =  0.00039712901222345594\n",
      "step= 1834 ; loss =  0.0003969029011045212\n",
      "step= 1835 ; loss =  0.00039667704337786967\n",
      "step= 1836 ; loss =  0.0003964514386205776\n",
      "step= 1837 ; loss =  0.0003962260864106383\n",
      "step= 1838 ; loss =  0.00039600098632700084\n",
      "step= 1839 ; loss =  0.00039577613794953713\n",
      "step= 1840 ; loss =  0.000395551540859055\n",
      "step= 1841 ; loss =  0.00039532719463727847\n",
      "step= 1842 ; loss =  0.00039510309886686267\n",
      "step= 1843 ; loss =  0.00039487925313139415\n",
      "step= 1844 ; loss =  0.00039465565701535184\n",
      "step= 1845 ; loss =  0.0003944323101041553\n",
      "step= 1846 ; loss =  0.0003942092119841293\n",
      "step= 1847 ; loss =  0.000393986362242513\n",
      "step= 1848 ; loss =  0.00039376376046745213\n",
      "step= 1849 ; loss =  0.00039354140624800856\n",
      "step= 1850 ; loss =  0.0003933192991741216\n",
      "step= 1851 ; loss =  0.00039309743883667194\n",
      "step= 1852 ; loss =  0.0003928758248274012\n",
      "step= 1853 ; loss =  0.00039265445673898234\n",
      "step= 1854 ; loss =  0.00039243333416494374\n",
      "step= 1855 ; loss =  0.00039221245669974613\n",
      "step= 1856 ; loss =  0.00039199182393871116\n",
      "step= 1857 ; loss =  0.0003917714354780579\n",
      "step= 1858 ; loss =  0.00039155129091488655\n",
      "step= 1859 ; loss =  0.0003913313898471868\n",
      "step= 1860 ; loss =  0.00039111173187383354\n",
      "step= 1861 ; loss =  0.0003908923165945487\n",
      "step= 1862 ; loss =  0.0003906731436099597\n",
      "step= 1863 ; loss =  0.0003904542125215578\n",
      "step= 1864 ; loss =  0.00039023552293169594\n",
      "step= 1865 ; loss =  0.00039001707444360524\n",
      "step= 1866 ; loss =  0.00038979886666137636\n",
      "step= 1867 ; loss =  0.00038958089918997345\n",
      "step= 1868 ; loss =  0.00038936317163521054\n",
      "step= 1869 ; loss =  0.00038914568360375507\n",
      "step= 1870 ; loss =  0.00038892843470314303\n",
      "step= 1871 ; loss =  0.00038871142454176163\n",
      "step= 1872 ; loss =  0.0003884946527288524\n",
      "step= 1873 ; loss =  0.00038827811887449015\n",
      "step= 1874 ; loss =  0.000388061822589618\n",
      "step= 1875 ; loss =  0.00038784576348600505\n",
      "step= 1876 ; loss =  0.00038762994117627386\n",
      "step= 1877 ; loss =  0.0003874143552738937\n",
      "step= 1878 ; loss =  0.00038719900539314716\n",
      "step= 1879 ; loss =  0.0003869838911491716\n",
      "step= 1880 ; loss =  0.0003867690121579412\n",
      "step= 1881 ; loss =  0.00038655436803624596\n",
      "step= 1882 ; loss =  0.00038633995840170894\n",
      "step= 1883 ; loss =  0.000386125782872793\n",
      "step= 1884 ; loss =  0.00038591184106876884\n",
      "step= 1885 ; loss =  0.0003856981326097236\n",
      "step= 1886 ; loss =  0.000385484657116601\n",
      "step= 1887 ; loss =  0.0003852714142111163\n",
      "step= 1888 ; loss =  0.00038505840351582657\n",
      "step= 1889 ; loss =  0.00038484562465410224\n",
      "step= 1890 ; loss =  0.0003846330772501112\n",
      "step= 1891 ; loss =  0.00038442076092884533\n",
      "step= 1892 ; loss =  0.0003842086753160917\n",
      "step= 1893 ; loss =  0.0003839968200384474\n",
      "step= 1894 ; loss =  0.0003837851947233194\n",
      "step= 1895 ; loss =  0.00038357379899888735\n",
      "step= 1896 ; loss =  0.0003833626324941666\n",
      "step= 1897 ; loss =  0.0003831516948389379\n",
      "step= 1898 ; loss =  0.00038294098566379306\n",
      "step= 1899 ; loss =  0.00038273050460011746\n",
      "step= 1900 ; loss =  0.00038252025128006703\n",
      "step= 1901 ; loss =  0.00038231022533660275\n",
      "step= 1902 ; loss =  0.0003821004264034637\n",
      "step= 1903 ; loss =  0.0003818908541151746\n",
      "step= 1904 ; loss =  0.0003816815081070425\n",
      "step= 1905 ; loss =  0.00038147238801515115\n",
      "step= 1906 ; loss =  0.00038126349347636547\n",
      "step= 1907 ; loss =  0.00038105482412831667\n",
      "step= 1908 ; loss =  0.00038084637960941905\n",
      "step= 1909 ; loss =  0.00038063815955884995\n",
      "step= 1910 ; loss =  0.0003804301636165559\n",
      "step= 1911 ; loss =  0.00038022239142326353\n",
      "step= 1912 ; loss =  0.00038001484262044\n",
      "step= 1913 ; loss =  0.00037980751685033485\n",
      "step= 1914 ; loss =  0.0003796004137559555\n",
      "step= 1915 ; loss =  0.0003793935329810625\n",
      "step= 1916 ; loss =  0.0003791868741701793\n",
      "step= 1917 ; loss =  0.00037898043696856816\n",
      "step= 1918 ; loss =  0.0003787742210222632\n",
      "step= 1919 ; loss =  0.0003785682259780511\n",
      "step= 1920 ; loss =  0.0003783624514834533\n",
      "step= 1921 ; loss =  0.0003781568971867335\n",
      "step= 1922 ; loss =  0.00037795156273692055\n",
      "step= 1923 ; loss =  0.0003777464477837615\n",
      "step= 1924 ; loss =  0.00037754155197776765\n",
      "step= 1925 ; loss =  0.0003773368749701904\n",
      "step= 1926 ; loss =  0.0003771324164129803\n",
      "step= 1927 ; loss =  0.00037692817595887085\n",
      "step= 1928 ; loss =  0.00037672415326130506\n",
      "step= 1929 ; loss =  0.0003765203479744446\n",
      "step= 1930 ; loss =  0.00037631675975321137\n",
      "step= 1931 ; loss =  0.0003761133882532341\n",
      "step= 1932 ; loss =  0.000375910233130869\n",
      "step= 1933 ; loss =  0.0003757072940431973\n",
      "step= 1934 ; loss =  0.0003755045706480279\n",
      "step= 1935 ; loss =  0.0003753020626038701\n",
      "step= 1936 ; loss =  0.0003750997695699791\n",
      "step= 1937 ; loss =  0.0003748976912063073\n",
      "step= 1938 ; loss =  0.0003746958271735228\n",
      "step= 1939 ; loss =  0.0003744941771330058\n",
      "step= 1940 ; loss =  0.0003742927407468634\n",
      "step= 1941 ; loss =  0.00037409151767787876\n",
      "step= 1942 ; loss =  0.00037389050758957604\n",
      "step= 1943 ; loss =  0.0003736897101461627\n",
      "step= 1944 ; loss =  0.0003734891250125457\n",
      "step= 1945 ; loss =  0.00037328875185435546\n",
      "step= 1946 ; loss =  0.00037308859033790854\n",
      "step= 1947 ; loss =  0.00037288864013020084\n",
      "step= 1948 ; loss =  0.00037268890089895654\n",
      "step= 1949 ; loss =  0.00037248937231257404\n",
      "step= 1950 ; loss =  0.0003722900540401577\n",
      "step= 1951 ; loss =  0.000372090945751485\n",
      "step= 1952 ; loss =  0.0003718920471170207\n",
      "step= 1953 ; loss =  0.00037169335780794504\n",
      "step= 1954 ; loss =  0.00037149487749608734\n",
      "step= 1955 ; loss =  0.00037129660585398473\n",
      "step= 1956 ; loss =  0.00037109854255484116\n",
      "step= 1957 ; loss =  0.00037090068727254347\n",
      "step= 1958 ; loss =  0.0003707030396816648\n",
      "step= 1959 ; loss =  0.0003705055994574478\n",
      "step= 1960 ; loss =  0.00037030836627580875\n",
      "step= 1961 ; loss =  0.00037011133981333747\n",
      "step= 1962 ; loss =  0.00036991451974729235\n",
      "step= 1963 ; loss =  0.00036971790575559665\n",
      "step= 1964 ; loss =  0.00036952149751685615\n",
      "step= 1965 ; loss =  0.0003693252947103311\n",
      "step= 1966 ; loss =  0.0003691292970159452\n",
      "step= 1967 ; loss =  0.00036893350411428905\n",
      "step= 1968 ; loss =  0.00036873791568661155\n",
      "step= 1969 ; loss =  0.00036854253141481745\n",
      "step= 1970 ; loss =  0.00036834735098146876\n",
      "step= 1971 ; loss =  0.00036815237406979425\n",
      "step= 1972 ; loss =  0.0003679576003636596\n",
      "step= 1973 ; loss =  0.00036776302954759447\n",
      "step= 1974 ; loss =  0.000367568661306775\n",
      "step= 1975 ; loss =  0.0003673744953270218\n",
      "step= 1976 ; loss =  0.0003671805312948055\n",
      "step= 1977 ; loss =  0.00036698676889724955\n",
      "step= 1978 ; loss =  0.0003667932078221051\n",
      "step= 1979 ; loss =  0.00036659984775777826\n",
      "step= 1980 ; loss =  0.00036640668839332\n",
      "step= 1981 ; loss =  0.00036621372941839493\n",
      "step= 1982 ; loss =  0.00036602097052333585\n",
      "step= 1983 ; loss =  0.00036582841139909237\n",
      "step= 1984 ; loss =  0.0003656360517372497\n",
      "step= 1985 ; loss =  0.000365443891230028\n",
      "step= 1986 ; loss =  0.00036525192957027875\n",
      "step= 1987 ; loss =  0.00036506016645148145\n",
      "step= 1988 ; loss =  0.00036486860156774973\n",
      "step= 1989 ; loss =  0.0003646772346138057\n",
      "step= 1990 ; loss =  0.00036448606528501174\n",
      "step= 1991 ; loss =  0.0003642950932773446\n",
      "step= 1992 ; loss =  0.00036410431828741327\n",
      "step= 1993 ; loss =  0.00036391374001241777\n",
      "step= 1994 ; loss =  0.0003637233581502186\n",
      "step= 1995 ; loss =  0.00036353317239925777\n",
      "step= 1996 ; loss =  0.00036334318245860483\n",
      "step= 1997 ; loss =  0.0003631533880279458\n",
      "step= 1998 ; loss =  0.00036296378880756663\n",
      "step= 1999 ; loss =  0.00036277438449837634\n"
     ]
    }
   ],
   "source": [
    "for k in range(2000):\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss = sum([(yout-ygt)**2 for ygt, yout in zip(ys, ypred)])\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "    loss.backward()\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 * p.grad \n",
    "    print('step=', k, '; loss = ', loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9892050996256689),\n",
       " Value(data=-0.9914912303796503),\n",
       " Value(data=-0.9895255177706821),\n",
       " Value(data=0.9919918434092383)]"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0edc844b12264540fce523bae77b11b30744b56466622a2d59899aa8327a4f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
